<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
<meta name="baidu-site-verification" content="code-oCEdExorFr" />
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="fW8TTOKkJ22AYrbkjIZSXK1q7VYmUdGIjhfdDJ_2-9k">
  <meta name="msvalidate.01" content="true">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=EB Garamond:300,300italic,400,400italic,700,700italic|Cinzel Decorative:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-loading-bar.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"wjykl22.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":300,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
<meta property="og:type" content="website">
<meta property="og:title" content="韭零后">
<meta property="og:url" content="https://wjykl22.github.io/page/2/index.html">
<meta property="og:site_name" content="韭零后">
<meta property="og:description" content="世界上有两样东西不可直视，一是太阳，二是人心">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Jiyang">
<meta property="article:tag" content="keywords">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://wjykl22.github.io/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>
<link rel="stylesheet" type="text/css" href="/css/injector.css" />
  <title>韭零后</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="韭零后" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">韭零后</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">公元1996 - ?</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-主页">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>主页</a>

  </li>
        <li class="menu-item menu-item-关于">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-标签">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-目录">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>目录</a>

  </li>
        <li class="menu-item menu-item-结构">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>结构</a>

  </li>
        <li class="menu-item menu-item-站点地图">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
        <li class="menu-item menu-item-公益">

    <a href="/404.html" rel="section"><i class="fa fa-heartbeat fa-fw"></i>公益</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/fe577f0d.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/fe577f0d.html" class="post-title-link" itemprop="url">上升和下降窗口</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-02 10:16:47" itemprop="dateCreated datePublished" datetime="2020-08-02T10:16:47+08:00">2020-08-02</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-28 19:30:10" itemprop="dateModified" datetime="2020-08-28T19:30:10+08:00">2020-08-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/" itemprop="url" rel="index"><span itemprop="name">投资</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/%E6%8A%80%E6%9C%AF%E9%9D%A2/" itemprop="url" rel="index"><span itemprop="name">技术面</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/%E6%8A%80%E6%9C%AF%E9%9D%A2/%E8%9C%A1%E7%83%9B%E5%9B%BE/" itemprop="url" rel="index"><span itemprop="name">蜡烛图</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/%E6%8A%80%E6%9C%AF%E9%9D%A2/%E8%9C%A1%E7%83%9B%E5%9B%BE/%E7%BB%84%E5%90%88%E5%BD%A2%E6%80%81/" itemprop="url" rel="index"><span itemprop="name">组合形态</span></a>
                </span>
            </span>

          
            <span id="/archives/fe577f0d.html" class="post-meta-item leancloud_visitors" data-flag-title="上升和下降窗口" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/fe577f0d.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/fe577f0d.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>91</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>和“跳空”指代的是同一个意思：价格运动出现了一个没有发生任何交易行为的价格区域。</p>
<h2 id="上升窗口">上升窗口</h2>
<ul>
<li>最高点和后一根蜡烛线的最低点之间存在价格缺口</li>
<li>是一种看涨信号</li>
<li>上升窗口形成后将会称为支撑位</li>
</ul>
<p><img src="/archives/fe577f0d/image-20200802102757016.png" alt="image-20200802102757016" style="zoom:67%;"></p>
<h2 id="下降窗口">下降窗口</h2>
<p><img src="/archives/fe577f0d/image-20200802103136973.png" alt="image-20200802103136973" style="zoom: 50%;"></p>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/11684b86.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/11684b86.html" class="post-title-link" itemprop="url">平头、乌鸦和士兵</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-01 20:51:41" itemprop="dateCreated datePublished" datetime="2020-08-01T20:51:41+08:00">2020-08-01</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-28 19:30:10" itemprop="dateModified" datetime="2020-08-28T19:30:10+08:00">2020-08-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/" itemprop="url" rel="index"><span itemprop="name">投资</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/%E6%8A%80%E6%9C%AF%E9%9D%A2/" itemprop="url" rel="index"><span itemprop="name">技术面</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/%E6%8A%80%E6%9C%AF%E9%9D%A2/%E8%9C%A1%E7%83%9B%E5%9B%BE/" itemprop="url" rel="index"><span itemprop="name">蜡烛图</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/%E6%8A%80%E6%9C%AF%E9%9D%A2/%E8%9C%A1%E7%83%9B%E5%9B%BE/%E7%BB%84%E5%90%88%E5%BD%A2%E6%80%81/" itemprop="url" rel="index"><span itemprop="name">组合形态</span></a>
                </span>
            </span>

          
            <span id="/archives/11684b86.html" class="post-meta-item leancloud_visitors" data-flag-title="平头、乌鸦和士兵" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/11684b86.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/11684b86.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>358</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="平头形态">平头形态</h2>
<ul>
<li>两根或者多根相同最高价和相同最低价的蜡烛线形成</li>
<li>理想情况
<ul>
<li>第一根蜡烛线是一个较长实体</li>
<li>第二交易日实体较小
<ul>
<li>可以是纺锤线，流星线，上吊线，乌云盖等极具变化的形态组合</li>
</ul></li>
</ul></li>
</ul>
<p><img src="/archives/11684b86/image-20200801205756971.png" alt="image-20200801205756971" style="zoom:67%;"></p>
<blockquote>
<p><code>注意：</code>平头形态在日线和日内分时并不重要（除非与其他指标相配合），但是在周线和月线级别需要引起重视</p>
</blockquote>
<h2 id="黑乌鸦">黑乌鸦</h2>
<p>该形态出现在一波上涨的高位处，预示着下跌还将继续</p>
<ul>
<li>组成：三根收盘价在当天最低点或者接近当天最低点的阴线构成</li>
<li>显示出现于上升趋势中，作为顶部的反转信号</li>
</ul>
<blockquote>
<p>立项情况下，每根黑色蜡烛线的开盘价位于前一根蜡烛实体的内部</p>
</blockquote>
<p><img src="/archives/11684b86/image-20200801210142084.png" alt="image-20200801210142084" style="zoom: 50%;"></p>
<h3 id="红色三兵">红色三兵</h3>
<ul>
<li>当天的收盘价都处于当天高点的附近</li>
</ul>
<p>和黑乌鸦相似，预示着上涨还将继续，最佳情况是开盘价都位于每根蜡烛的实体内部</p>
<p><img src="/archives/11684b86/image-20200801210437954.png" alt="image-20200801210437954" style="zoom:67%;"></p>
<blockquote>
<p>要注意以上两种形态并不是买入和卖出信号，只是意味着状态的持续，建仓需要格外小心，需要等待回落到支撑位、</p>
<p>它出现在上涨还是下跌行情中并不重要</p>
</blockquote>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/70896bd9.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/70896bd9.html" class="post-title-link" itemprop="url">孕线与十字孕线、启明星与黄昏线</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-01 17:35:42" itemprop="dateCreated datePublished" datetime="2020-08-01T17:35:42+08:00">2020-08-01</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-28 19:30:10" itemprop="dateModified" datetime="2020-08-28T19:30:10+08:00">2020-08-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/" itemprop="url" rel="index"><span itemprop="name">投资</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/%E6%8A%80%E6%9C%AF%E9%9D%A2/" itemprop="url" rel="index"><span itemprop="name">技术面</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/%E6%8A%80%E6%9C%AF%E9%9D%A2/%E8%9C%A1%E7%83%9B%E5%9B%BE/" itemprop="url" rel="index"><span itemprop="name">蜡烛图</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/%E6%8A%80%E6%9C%AF%E9%9D%A2/%E8%9C%A1%E7%83%9B%E5%9B%BE/%E7%BB%84%E5%90%88%E5%BD%A2%E6%80%81/" itemprop="url" rel="index"><span itemprop="name">组合形态</span></a>
                </span>
            </span>

          
            <span id="/archives/70896bd9.html" class="post-meta-item leancloud_visitors" data-flag-title="孕线与十字孕线、启明星与黄昏线" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/70896bd9.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/70896bd9.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>281</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="孕线">孕线</h2>
<ul>
<li>第一根蜡烛是一个远超一般长度的红色和绿色实体</li>
<li>第二根蜡烛实体被第一根蜡烛包裹</li>
</ul>
<p><img src="/archives/70896bd9/image-20200801173944948.png" alt="image-20200801173944948" style="zoom:67%;"></p>
<h2 id="十字孕线">十字孕线</h2>
<p>被包裹的蜡烛是一个十字星形态</p>
<p><img src="/archives/70896bd9/image-20200801174305878.png" alt="image-20200801174305878" style="zoom:67%;"></p>
<blockquote>
<p>该种形态可以和锤子线，流星线和十字星线等单根蜡烛形态结合来看</p>
</blockquote>
<h2 id="启明星">启明星</h2>
<ul>
<li>三根实体形成（中间一根是小实体，称为<code>星线</code>）</li>
<li>上升和下降趋势中，星线和第一根实体形成跳空缺口</li>
<li>第三根和星线之间也出现跳空缺口</li>
<li>使得星线实体孤立出现在趋势的末尾位置</li>
</ul>
<blockquote>
<p>理想状况下实体之间没有重叠，影线和中间蜡烛颜色无所谓</p>
</blockquote>
<p><img src="/archives/70896bd9/image-20200801202609720.png" alt="image-20200801202609720" style="zoom:67%;"></p>
<h2 id="十字启明星">十字启明星</h2>
<p>上方的星形蜡烛是一个十字星形态</p>
<p><img src="/archives/70896bd9/image-20200801202714455.png" alt="image-20200801202714455" style="zoom:67%;"></p>
<blockquote>
<p>启明星形态可以配合成交量，以底部形态为例，第一根阴线配合较小成交量，第三根阳线突然放出较大成交量，说明市场力量正在激起一波新的市场走势。</p>
</blockquote>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/b4c92d84.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/b4c92d84.html" class="post-title-link" itemprop="url">刺透、乌云盖顶、吞没以及反击线</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-01 09:42:39" itemprop="dateCreated datePublished" datetime="2020-08-01T09:42:39+08:00">2020-08-01</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-03 14:05:34" itemprop="dateModified" datetime="2020-08-03T14:05:34+08:00">2020-08-03</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/" itemprop="url" rel="index"><span itemprop="name">投资</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/%E6%8A%80%E6%9C%AF%E9%9D%A2/" itemprop="url" rel="index"><span itemprop="name">技术面</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/%E6%8A%80%E6%9C%AF%E9%9D%A2/%E8%9C%A1%E7%83%9B%E5%9B%BE/" itemprop="url" rel="index"><span itemprop="name">蜡烛图</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/%E6%8A%80%E6%9C%AF%E9%9D%A2/%E8%9C%A1%E7%83%9B%E5%9B%BE/%E7%BB%84%E5%90%88%E5%BD%A2%E6%80%81/" itemprop="url" rel="index"><span itemprop="name">组合形态</span></a>
                </span>
            </span>

          
            <span id="/archives/b4c92d84.html" class="post-meta-item leancloud_visitors" data-flag-title="刺透、乌云盖顶、吞没以及反击线" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/b4c92d84.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/b4c92d84.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>559</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>两根蜡烛图会比一根蜡烛传达的信息更加准确：</p>
<ul>
<li>第一根蜡说明市场达到顶部或者底部</li>
<li>第二根蜡烛进行确认</li>
</ul>
<p>三根蜡烛会更加准确</p>
<ul>
<li>第一根说明之前的趋势正在继续</li>
<li>第二根蜡烛传达见顶或者触底的信息</li>
<li>第三根蜡烛对反转信号的有效性进行确认</li>
</ul>
<h2 id="刺透形态">刺透形态</h2>
<h3 id="形态条件">形态条件</h3>
<ol type="1">
<li>处于下降趋势，超卖过程中</li>
<li>下降趋势中，第一根蜡烛是一个绿色实体</li>
<li>第二根红色蜡烛低开，向上穿入黑色实体内部超过<span class="math inline">\(1/2\)</span>位置处</li>
</ol>
<p><img src="/archives/b4c92d84/image-20200801105812622.png" alt="image-20200801105812622" style="zoom: 50%;"></p>
<h2 id="乌云盖形态">乌云盖形态</h2>
<ol type="1">
<li>处于上涨趋势中，超买状态</li>
<li>第一根蜡烛红色实体，第二根蜡烛绿色实体</li>
<li>第二根蜡烛开盘高于前一根红色实体最高或收盘价，收盘到前一根红色实体开盘价附近</li>
</ol>
<p><img src="/archives/b4c92d84/image-20200801110106072.png" alt="image-20200801110106072" style="zoom: 50%;"></p>
<h2 id="吞没形态">吞没形态</h2>
<ul>
<li>蜡烛的颜色需要被区分</li>
</ul>
<p>只需要吞没前一根线的实体部分，并不必须吞没影线</p>
<p><img src="/archives/b4c92d84/image-20200801110228675.png" alt="image-20200801110228675" style="zoom: 50%;"></p>
<h2 id="反击线形态">反击线形态</h2>
<p>反击线会稍微弱于乌云盖和吞没形态，但是同样会起到预示作用</p>
<p><img src="/archives/b4c92d84/image-20200801110551994.png" alt="image-20200801110551994" style="zoom: 50%;"></p>
<h2 id="实战例题">实战例题</h2>
<p><img src="/archives/b4c92d84/image-20200801172831061.png" alt="image-20200801172831061" style="zoom:67%;"></p>
<p>说明：上方虚线部分是我们需要反弹到的目标价位，我们需要寻找较为合适的买点，对比收盘价，X的收盘价不适合买入，来到Y收盘价后适合买入。</p>
<p>原因：</p>
<ul>
<li>X处出现了长下影线的锤子线，其最低价形成了一个局部的支撑位</li>
<li>考察X收盘距离目标价位和支撑位的距离，交易的收益和风险并不具有吸引力
<ul>
<li>支撑位变成了买入之后的止损位</li>
<li>而目标价位到止损位之间的距离差不多，所以综合衡量之下，并不诱人</li>
</ul></li>
<li>Y处的收盘价再非常接近局部支撑位附近
<ul>
<li>将支撑位设置为止损位</li>
<li>距离目标价位的距离显然大于止损位的距离，收益和风险比较好，适合买入</li>
</ul></li>
</ul>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/88211b35.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/88211b35.html" class="post-title-link" itemprop="url">分布式机器学习量化通信综述</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-31 16:03:49" itemprop="dateCreated datePublished" datetime="2020-07-31T16:03:49+08:00">2020-07-31</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-11 13:53:54" itemprop="dateModified" datetime="2020-10-11T13:53:54+08:00">2020-10-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">分布式机器学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%9A%E4%BF%A1%E4%BC%98%E5%8C%96/" itemprop="url" rel="index"><span itemprop="name">通信优化</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%9A%E4%BF%A1%E4%BC%98%E5%8C%96/%E6%A2%AF%E5%BA%A6%E5%8E%8B%E7%BC%A9/" itemprop="url" rel="index"><span itemprop="name">梯度压缩</span></a>
                </span>
            </span>

          
            <span id="/archives/88211b35.html" class="post-meta-item leancloud_visitors" data-flag-title="分布式机器学习量化通信综述" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/88211b35.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/88211b35.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>102k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1:33</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          此文加密，请输入密码
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/archives/88211b35.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/1b1e994e.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/1b1e994e.html" class="post-title-link" itemprop="url">1 Bits SGD and its Application to Data Parallel Distributed Training of Speach DNNs</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-31 14:45:54" itemprop="dateCreated datePublished" datetime="2020-07-31T14:45:54+08:00">2020-07-31</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-11 13:45:55" itemprop="dateModified" datetime="2020-10-11T13:45:55+08:00">2020-10-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">分布式机器学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%9A%E4%BF%A1%E4%BC%98%E5%8C%96/" itemprop="url" rel="index"><span itemprop="name">通信优化</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%9A%E4%BF%A1%E4%BC%98%E5%8C%96/%E6%A2%AF%E5%BA%A6%E5%8E%8B%E7%BC%A9/" itemprop="url" rel="index"><span itemprop="name">梯度压缩</span></a>
                </span>
            </span>

          
            <span id="/archives/1b1e994e.html" class="post-meta-item leancloud_visitors" data-flag-title="1 Bits SGD and its Application to Data Parallel Distributed Training of Speach DNNs" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/1b1e994e.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/1b1e994e.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="摘要">摘要</h2>
<p>本文主要提出了一种比较激进的梯度量化方法，它可以将梯度中的每一位都量化为1bit，而且每次的量化误差都会补偿进下一轮量化梯度当中，因此称为带有误差补偿的1bit梯度量化方法。</p>
<blockquote>
<p>值得一提的是，本文是将量化引入分布式机器学习的开山之作，同时，这种非常激进（因为量化为1bit）的量化方式，极大减小了通信成本，而且误差补偿的方法非常具有启发性。</p>
</blockquote>
<p>本文主要针对并行SGD的AdaGrad、自动最小批量大小选择，双缓冲机制以及模型并行等多个方面进行探究。在实验上证实了量化和AdaGrad相结合会有一定的准确率提升。</p>
<h2 id="数据并行的确定分布式sgd训练">数据并行的确定分布式SGD训练</h2>
<p>错误的反向传播方法是训练DNN模型常用的方法，它形成了一种随机梯度下降算法。随机梯度下降算法通用形式如下： <span class="math display">\[
\begin{aligned}
\lambda(t+N) &amp;=\lambda(t)+\epsilon(t) \cdot G(t) \\
G(t) &amp;=\left.\sum_{\tau=t}^{t+N-1} \frac{\partial \mathcal{F}_{\lambda}(o(\tau))}{\partial \lambda}\right|_{\lambda=\lambda(t)}
\end{aligned}
\]</span> 其中<span class="math inline">\(\lambda(t)\)</span>代表当前索引<span class="math inline">\(t\)</span>采样下的模型，它的增长步长是<span class="math inline">\(N\)</span>，也就是数据采样的批量大小为<span class="math inline">\(N\)</span>。<span class="math inline">\(\mathcal{F}_{\lambda}\)</span>是样本向量为<span class="math inline">\(o(\tau)\)</span>的函数的部分梯度。<span class="math inline">\(\epsilon(t)\)</span>表示学习率。</p>
<h3 id="数据并行的分布式sgd">数据并行的分布式SGD</h3>
<p>对于上述数据并行训练来说，最佳节点数量<span class="math inline">\(\hat{K}\)</span>能够使得节点中计算和数据通信完全重叠，此时可以保证通信和计算资源是饱和的，也就是能够达到并行的最优化： <span class="math display">\[
T_{\text {calc }}(\hat{K})=T_{\text {comm }}(\hat{K})
\]</span> <span class="math inline">\(T_{\text {calc }}\)</span>和<span class="math inline">\(T_{\text {comm }}\)</span>分别是节点上每个小批量所需要的的计算和通信时间。如果我们将计算和通信开销继续细分，我们就能够求出最优节点数量 <span class="math display">\[
\hat{K}=\frac{N / 2 \cdot T_{\mathrm{calc}}^{\mathrm{frm}}+C \cdot T_{\mathrm{calc}}^{\mathrm{post}}}{\frac{1}{Z} \cdot T_{\mathrm{comm}}^{\mathrm{float}}-T_{\mathrm{calc}}^{\mathrm{udd}}}
\]</span> <img src="/archives/1b1e994e/image-20200731151547791.png" alt="image-20200731151547791" style="zoom:67%;"></p>
<p>其中：</p>
<p>事实上，将每个维度精度为<span class="math inline">\(Z=32\)</span>的数据压缩为1bit</p>
<ul>
<li><p><span class="math inline">\(T_{\mathrm{calc}}^{\mathrm{frm}}\)</span>表示处理数据的时间，这部分是可以并行的</p>
<p>与参数M的关系：<span class="math inline">\(\propto \frac{M}{\text { FLOPS }}\)</span></p></li>
<li><p><span class="math inline">\(T_{\mathrm{calc}}^{\mathrm{post}}\)</span>表示对梯度后处理的时间，比如momentum+AdaGrad</p>
<p>与参数M的关系：<span class="math inline">\(\propto \frac{M}{\text { RAM bindwidth }}\)</span></p></li>
<li><p><span class="math inline">\(T_{\mathrm{comm}}^{\mathrm{float}}\)</span>传输梯度（由单精度浮点数表示）的时间</p>
<p>与参数M的关系：<span class="math inline">\(\propto \frac{M}{\text { Network bindwidth }}\)</span></p></li>
<li><p><span class="math inline">\(T_{\mathrm{calc}}^{\mathrm{udd}}\)</span>模型更新时间，相对于<span class="math inline">\(K\)</span>来说是固定的</p>
<p>与参数M的关系：<span class="math inline">\(\propto \frac{M}{\text { RAM bindwidth }}\)</span></p></li>
</ul>
<h3 id="双缓冲机制">双缓冲机制</h3>
<p>为了实现更高的并行度，作者提出了双缓冲（double buffering）的概念，即在每个节点上把一个小批量分成两部分在交换其中一部分的梯度时进行另一部分的计算。然而，双缓冲机制会引入额外的更新开销（该开销是进行梯度聚合过程中产生的），当通信开销小于更新开销（即<span class="math inline">\(T_{\text {comm}}^{\text {flat}}&lt;T_{\text {calc}}^{\text {upd}}\)</span>）公式不在成立，双缓冲机制失去作用。</p>
<blockquote>
<p>双缓冲机制的方式很好，可以用于参数服务器架构，使得通信和梯度计算之间过程的重叠，有助于更好地并行。</p>
</blockquote>
<h3 id="误差补偿的1bit量化">误差补偿的1Bit量化</h3>
<p>本文最核心的部分就是减小在数据并行过程中，节点之间进行梯度传输过程中所需要的带宽消耗。（1）本文中的数据并行默认只交换荼毒，并不交换模型；（2）在数据交换的时候对梯度进行量化。</p>
<p>为了降低量化误差带来的负面影响，作者使用了误差补偿技术：每次量化时，把上一次迭代的量化误差加到本次迭代的梯度上，然后再进行量化，接着求出本次量化操作的误差。这种误差补偿机制可以确保所有的梯度都会再一定程度上对模型更新产生作用，只不过这种作用分散在不同的迭代中——类似于一种延迟更新的形式。作者指出，使用误差补偿后，就可以在几乎不损失模型精度的情况下将梯度由32位量化成1位。 <span class="math display">\[
\begin{aligned}
G_{i j \ell}^{\text {quant }}(t) &amp;=\mathcal{Q}\left(G_{i j \ell}(t)+\Delta_{i j \ell}(t-N)\right) \\
\Delta_{i j \ell}(t) &amp;=G_{i j \ell}(t)-\mathcal{Q}^{-1}\left(G_{i j \ell}^{\text {quant }}(t)\right)
\end{aligned}
\]</span> 其中<span class="math inline">\(\mathcal{Q}(\cdot)\)</span>表示量化函数，<span class="math inline">\(G_{i j \ell}^{\text {quant }}(t)\)</span>表示量化之后的整型数值。我们在量化过程中会保证<span class="math inline">\(\Delta_{i j \ell}(t)\)</span>被加到下一轮的梯度过程中（也称为了误差补偿机制）。</p>
<p>举个例子，在具体的实现上，比较简单的方法是将大于<span class="math inline">\(0\)</span>的梯度值编码成为<span class="math inline">\(1\)</span>，小于等于<span class="math inline">\(0\)</span>的梯度值编码为<span class="math inline">\(0\)</span>。在解码的时候，将<span class="math inline">\(1\)</span>编码为<span class="math inline">\(+1\)</span>，将<span class="math inline">\(0\)</span>解码为<span class="math inline">\(-1\)</span>，在进行聚合操作。</p>
<h3 id="系统描述">系统描述</h3>
<p>作者从最优节点数的公式当中总结出如下提高并行度的方法：</p>
<ol type="1">
<li>增加<span class="math inline">\(N\)</span>，也就是尽可能使得小批量的规模更大</li>
<li>增加<span class="math inline">\(Z\)</span>，尽可能大得压缩通信数据量</li>
<li>减少固定消耗<span class="math inline">\(T_{\mathrm{calc}}^{\mathrm{udd}}\)</span></li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/2932556.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/2932556.html" class="post-title-link" itemprop="url">A Survey on Methods and Theories of Quantized Neural Networks</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-29 14:30:28" itemprop="dateCreated datePublished" datetime="2020-07-29T14:30:28+08:00">2020-07-29</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-11 13:45:32" itemprop="dateModified" datetime="2020-10-11T13:45:32+08:00">2020-10-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">分布式机器学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%9A%E4%BF%A1%E4%BC%98%E5%8C%96/" itemprop="url" rel="index"><span itemprop="name">通信优化</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%9A%E4%BF%A1%E4%BC%98%E5%8C%96/%E6%A2%AF%E5%BA%A6%E5%8E%8B%E7%BC%A9/" itemprop="url" rel="index"><span itemprop="name">梯度压缩</span></a>
                </span>
            </span>

          
            <span id="/archives/2932556.html" class="post-meta-item leancloud_visitors" data-flag-title="A Survey on Methods and Theories of Quantized Neural Networks" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/2932556.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/2932556.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>9.3k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>8 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="摘要">摘要</h2>
<p>当下流行的深度神经网络具有非常复杂的结构，训练时需要消耗大量的内存和电源；在移动端和边缘设备等资源限制的情况下难以发挥作用，而量化则是解决上述问题的办法之一。原来的神经网络权重、激活和梯度都需要采用<span class="math inline">\(32bit\)</span>精度的浮点表示，但是采用量化表示只需要整型或者二进制即可，大大减少了模型尺寸和资源消耗。这是一篇综述，从不同方面给出了量化神经网络的一些方法，同时也罗列了目前在这些方面遇到的挑战。</p>
<h2 id="介绍">介绍</h2>
<h3 id="神经网络">神经网络</h3>
<p>本文介绍了下面几种神经网络，比较基础，这里就不做赘述</p>
<h4 id="前馈神经网络">前馈神经网络</h4>
<h4 id="卷积神经网络">卷积神经网络</h4>
<p>值得一提的是以下这些卷积神经网络结构：</p>
<ul>
<li>AlexNet[Krizhevsky et al., 2012<a href="#refer-anchor-1"><sup>1</sup></a>]</li>
<li>VGGNet[Simonyan and Zisserman, 2014<a href="#refer-anchor-2"><sup>2</sup></a>]</li>
<li>GoogleNet[Szegedy et al., 2015<a href="#refer-anchor-3"><sup>3</sup></a>]</li>
<li>ResNet[He et al., 2016a<a href="#refer-anchor-4"><sup>4</sup></a>]</li>
</ul>
<p>这四个架构非常广泛地用在比较不同压缩和量化方法性能比较实验过程中，常常作为基准（baseline）。</p>
<h4 id="循环神经网络和lstm">循环神经网络和LSTM</h4>
<h3 id="量化神经网络">量化神经网络</h3>
<h4 id="术语介绍">术语介绍</h4>
<ul>
<li><strong>低精度</strong>（Low precision）：可能是最通用的概念。常规精度一般使用 FP32（32位浮点，单精度）存储模型权重；低精度则表示 FP16（半精度浮点），INT8（8位的定点整数）等等数值格式。不过目前低精度往往指代 INT8。</li>
<li><strong>混合精度</strong>（Mixed precision）在模型中使用 FP32 和 FP16 。 FP16 减少了一半的内存大小，但有些参数或操作符必须采用 FP32 格式才能保持准确度。如果您对该主题感兴趣，请查看 <a href="https://link.zhihu.com/?target=https%3A//devblogs.nvidia.com/mixed-precision-training-deep-neural-networks/" rel="external nofollow noreferrer">Mixed-Precision Training of Deep Neural Networks</a> 。</li>
<li><strong>量化</strong>一般指 INT8 。不过，根据存储一个权重元素所需的位数，还可以包括：
<ul>
<li><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1602.02830" rel="external nofollow noreferrer">二值神经网络</a>：在运行时权重和激活只取两种值（例如 +1，-1）的神经网络，以及在训练时计算参数的梯度。</li>
<li><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1605.04711" rel="external nofollow noreferrer">三元权重网络</a>：权重约束为+1,0和-1的神经网络。</li>
<li><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1603.05279" rel="external nofollow noreferrer">XNOR网络</a>：过滤器和卷积层的输入是二进制的。 XNOR 网络主要使用二进制运算来近似卷积。</li>
</ul></li>
</ul>
<h4 id="正文">正文</h4>
<p>目前，很多技术用在了量化神经网络方面。粗略地来看可以分成确定性量化和随机量化。在确定量化中，在量化值和真实值之间有一一对应的映射，而随机量化权重，激活和梯度则是离散分布。量化值是从离散分布中采样得到的。</p>
<p>在神经网络中有三个部分是可以进行量化的：权重、激活和梯度。量化这些部分的动机和方法是不同的。量化权重和激活层，我们得到更小的模型尺寸。在分布式训练的花镜中，我们能够通过量化梯度的方式节省通信消耗。一般来说，量化梯度比量化权重和激活更加困难，因为训练往往需要精度更高的梯度来保证算法的收敛。</p>
<p>我们通常采用编码本（codebook）来表示代表真实值的离散值。从密码本的表示来看，现有的工作可以将量化神经网络粗略的分成两类：固定编码本量化和自适应编码本量化。</p>
<p>在固定编码本量化中，权重经常被量化成提前定义好的编码，二自适应编码本是从数据中学习而来。一些普遍应用的密码本包括<span class="math inline">\(\{-1,1\}\)</span>，<span class="math inline">\(\{-1,0,1\}\)</span>或者二数幂或者二进制网络和三元权重网络等。</p>
<p>训练量化模型需要不断调整，而且量化网络并不容易理解，寻找新的量化方法以及配合理论分析是量化神经网络非常重要的一点。</p>
<h2 id="量化技术">量化技术</h2>
<h3 id="确定性量化">确定性量化</h3>
<h4 id="取整rounding">取整（Rounding）</h4>
<h5 id="主要内容">主要内容</h5>
<p>取证可能是对真实值最简单的量化，例如[Courbariaux et al., 2015]提出下面这种取整方法： <span class="math display">\[
x^{b}=\operatorname{sign}(x)=\left\{\begin{array}{ll}
+1 &amp; x \geq 0 \\
-1 &amp; \text { otherwise }
\end{array}\right.
\]</span> 其中<span class="math inline">\(x^b\)</span>表示二进制量，<span class="math inline">\(x\)</span>是真实量。这个方法可以应用在量化权重，激活和梯度中。在前向传播中，真实值权重能够产生输出。然而，在反向传播过程中，我们不能够通过<code>Sign(x)</code>来进行，因为它是离散的，到处都是梯度为零。通常采用的方法是“直通估计（straight through estimator）”（STE）[Hinton et al., 2012b]，它采用启发式的方法估计随机神经元的梯度。假设<span class="math inline">\(E\)</span>是损失函数，STE的前向和反向计算可以看成如下方式： <span class="math display">\[
\begin{array}{l}
\text { Forward: } \quad x^{b}=\operatorname{Sign}(x) \\
\text { Backward: } \frac{\partial E}{\partial x}=\frac{\partial E}{\partial x^{b}} \mathrm{I}_{|x| \leq 1}
\end{array}
\]</span> 其中<span class="math inline">\(\mathrm{I}_{|x| \leq 1}\)</span>是定义如下的指示函数： <span class="math display">\[
\mathrm{I}_{|x| \leq 1}=\left\{\begin{array}{ll}
1 &amp; |x| \leq 1 \\
0 &amp; \text { otherwise }
\end{array}\right.
\]</span> 为了对双精度进行取整，[Gupta et al., 2015]作者提出了如下的取整方式： <span class="math display">\[
\operatorname{Round}(x,[\mathrm{IL}, \mathrm{FL}])=\left\{\begin{array}{ll}
\lfloor x\rfloor &amp; \text { if }\lfloor x\rfloor \leq x \leq\lfloor x\rfloor+\frac{\epsilon}{2} \\
\lfloor x\rfloor+\epsilon &amp; \text { if }\lfloor x\rfloor+\frac{\epsilon}{2}&lt;x \leq\lfloor x\rfloor+\epsilon
\end{array}\right.
\]</span> 在固定点表达中，IL代表整数位的个数，FL表示分数位的个数。<span class="math inline">\(\epsilon\)</span>表示在固定点表达中能够表达的最小正数。<span class="math inline">\(\lfloor x\rfloor\)</span>被定义为<span class="math inline">\(\epsilon\)</span>的最大整数倍。对于超出此固定点格式范围的值，作者将它们规范化为固定点表示的下界或上界[Rastegari et al., 2016]。将上式扩展： <span class="math display">\[
\begin{array}{ll}
\text { Forward: } &amp; x^{b}=\operatorname{Sign}(x) \times \mathrm{E}_{F}(|x|) \\
\text { Backward: } &amp; \frac{\partial E}{\partial x}=\frac{\partial E}{\partial x^{b}}
\end{array}
\]</span> 其中<span class="math inline">\(\mathrm{E}_{F}(|x|)\)</span>表示每个输出通道的权值绝对值的平均值。</p>
<p>近期[Polino et al., 2018]提出了更加普遍的舍入函数： <span class="math display">\[
Q(x)=s c^{-1}(\hat{Q}(s c(x)))
\]</span> 其中<span class="math inline">\(sc(x)\)</span>是将值从任意范围缩放到<span class="math inline">\([0,1]\)</span>的缩放函数。<span class="math inline">\(\hat{Q}(x)\)</span>是实际的量化函数。给出量化等级参数<span class="math inline">\(s\)</span>，有<span class="math inline">\(s+1\)</span>等级的统一量化函数可以定义为： <span class="math display">\[
\hat{Q}(x, s)=\frac{\lfloor x s\rfloor}{s}+\frac{\xi}{s}
\]</span> 其中 <span class="math display">\[
\xi=\left\{\begin{array}{ll}
1 &amp; x s-\lfloor x s\rfloor&gt;\frac{1}{2} \\
0 &amp; \text { otherwise }
\end{array}\right.
\]</span> 这个量化函数的直觉是将<span class="math inline">\(x\)</span>分配到在<span class="math inline">\([0,1]\)</span>范围内<span class="math inline">\(s-1\)</span>个等间隔最接近的量化点。这是符号<span class="math inline">\(Sign(x)\)</span>函数的广义版本，能够将实值量化成多层。在[Shuang et al., 2018]中，作者提出了启发式摄入函数来量化一个市值为<span class="math inline">\(k\)</span>位的整数。 <span class="math display">\[
Q(x, k)=\operatorname{Clip}\left\{\sigma(k) \cdot \operatorname{round}\left[\frac{x}{\sigma(k)}\right],-1+\sigma(k), 1-\sigma(k)\right\}
\]</span> 想法是将真实值利用统一的距离<span class="math inline">\(\sigma(k)\)</span>进行量化，其中<span class="math inline">\(\sigma(k)=2^{1-k}\)</span>。<span class="math inline">\(Clip\)</span>将量化限制在<span class="math inline">\([-1+\sigma(k), 1-\sigma(k)]\)</span>范围内，<span class="math inline">\(round\)</span>用最近的离散点替换连续值。</p>
<h5 id="挑战">挑战</h5>
<p>挑战:使用四舍五入函数是将实值转换为量化值的简单方法。然而，每次四舍五入操作之后，网络性能可能会急剧下降。在训练过程中需要保持真实值作为参考，这会增加记忆开销。同时，由于使用离散值时参数空间要小得多，训练过程难以收敛。最后，舍入运算不能充分利用网络中权值的结构信息。</p>
<h4 id="向量量化">向量量化</h4>
<p>[Gong et al., 2014]是第一篇将向量量化考虑到神经网络压缩和量化中的。他主要的思想是将权重分组聚类，在推理时采用聚类中心代表每个组实际的权重。</p>
<p>[Han et al., 2015]，[Gong et al., 2014]等都对这种方式进行了改进，[Choi et al., 2016]指出这种方法有两个缺点，第一是不能够控制由于<code>k-means</code>算法造成的损失；第二是<code>k-means</code>算法不施加任何压缩比约束。为了解决这些问题，作者提出了一种Hessian加权k均值聚类方法。其基本思想是使用Hessian Weighted失真来测量因权值量化而导致的性能退化。这样可以防止那些对网络性能有较大影响的权值与原始值偏离太多。</p>
<p>有很多对向量量化的扩展方法，乘积量化[Gong et al., 2014]是一种将权重矩阵划分为许多不相交的子矩阵，并对每个子矩阵进行量化的方法。在[Wu et al., 2016]中，作者采用带误差修正的产品量化方法对网络参数进行量化，实现快速训练和测试。残差量化[Gong et al., 2014]将向量量化到k个聚类中，然后递归量化残差。在[Park et al., 2017]中，作者采用了类似于矢量量化的方法。他们使用了一个基于权重熵的想法[Guias¸u, 1971]来将权重分组到N个簇中。对于重要的权重范围有更多的簇。从而实现了自动灵活的多比特量化。</p>
<h5 id="挑战-1">挑战</h5>
<p>由于网络中权值的数量，k-means聚类的计算量很大。与四舍五入法相比，用向量化方法来实现二值权值比较困难。向量量化通常用于对预先训练的模型进行量化。因此，如果任务是从头训练量化网络，最好使用精心设计的四舍五入函数。向量量化忽略了网络的局部信息。</p>
<h4 id="量化最优化">量化最优化</h4>
<p>简单来说就是将量化作为最优化问题进行，此处暂时省略...</p>
<h3 id="随机量化">随机量化</h3>
<h4 id="随机舍入法random-rounding">随机舍入法（Random Rounding）</h4>
<p>在随机舍入法中，真实值和量化值有着一对一的对应。典型地，量化值的权重是从离散分布中采样而来，它是通过真实值进行参数化的。例如，[Courbariaux et al., 2015]提出了以下的随机近似方法： <span class="math display">\[
x^{b}=\left\{\begin{array}{ll}+1 &amp; \text { with probability } p=\sigma(x) \\ -1 &amp; \text { with probability } 1-p\end{array}\right.
\]</span> 其中<span class="math inline">\(\sigma\)</span>表示“hard sigmoid”函数 <span class="math display">\[
\sigma(x)=\operatorname{clip}\left(\frac{x+1}{2}, 0,1\right)=\max \left(0, \min \left(1, \frac{x+1}{2}\right)\right)
\]</span> 直观上来说，<span class="math inline">\(x\)</span>是一个正值，我们将以很高的概率量化到<span class="math inline">\(+1\)</span>，其他情况量化到<span class="math inline">\(-1\)</span>。这就给我们更加灵活的量化模式。在[Muller and Indi-veri, 2015]中，作者在整数规划中使用了这种思想。提出的随机四舍五入函数将每个实值概率映射到最近的离散点或第二最近的离散点，这取决于到对应点的距离。在[Lin et al., 2015]中，将二进随机四舍五入扩展到三元情形。</p>
<h5 id="挑战-2">挑战</h5>
<p>随机舍入提供了一种将噪声注入训练过程的方法。它可以作为一个正则化器和可提供条件计算。然而，使用随机的舍入方法，我们需要估计离散神经元的梯度。这样的估计往往有很高的方差。这一事实可能会导致训练过程中损失函数的振荡。[Bengio等人，2013]的工作提供了估计离散中性电子梯度的可能解决方案的概述。</p>
<h4 id="概率量化">概率量化</h4>
<p>暂无</p>
<h4 id="讨论">讨论</h4>
<p>上述量化技术使我们能够从不同的角度对网络进行量化。这些技术的优缺点可以指导我们在不同的情况下选择合适的技术。一般来说，如果我们想为硬件加速量化神经网络，确定性量化应该是首选，因为我们可以预先指定适当的量化级别，以便在专用硬件上运行量化的网络工作。这可以提高硬件的预测性能。四舍五入使我们能够以数据依赖的方式量化权重。这导致了条件计算[Bengio et al.， 2013]，可以增加神经网络的容量。概率量化与确定性量化的不同之处在于量化后的权重更具有可解释性。我们可以用概率量化的方法来理解权值的分布，并对网络的工作原理有更深入的了解。在概率量化的情况下，由于贝叶斯方法的正则化效果，我们也可以得到更稀疏的模型。</p>
<h2 id="量化对象分类">量化对象分类</h2>
<h3 id="权重量化">权重量化</h3>
<p>在[Zhou et al., 2017a]中，作者提出了增量式网络量化(INQ)，它包括三个步骤：权重划分、分组量化和再训练。他们以组的方式对权重进行组化，以允许某些权重组补偿由于其他组的量化而造成的准确性损失。[Gudovskiy and Rigazio, 2017]的工作将这种方法扩展到2次幂设置。</p>
<p>在[Lin et al., 2016]中，作者试图找到最优的不动点位宽跨层分配。他们研究了通过量化不同的层可以引入多少噪音。[Lin et al., 2017]使用多个二进制基的线性组合近似全精度权重。结果表明，二值神经网络在ImageNet数据集上首次取得了与全精度神经网络相当的预测精度。在[Moons et al., 2017]中，作者研究了如何发展节能量化神经网络。在[Guo et al., 2017]的工作中引入了网络素描来量化预先训练好的模型。其思想是使用二进制基来近似预先训练过的滤波器。他们首先提出了一种启发式算法来寻找二进制基础，然后提供了一个改进版本，以更好的近似。在[Mohamed Amer, 2018]中，作者提出了一种端到端训练框架来同时优化原始损失函数、量化误差和总比特数。然而，其精度无法与其他量化神经网络相比。</p>
<h3 id="梯度量化">梯度量化</h3>
<p>梯度量化的应用场景一般是为了在分布式训练过程中减小通信消耗。如下图就是为神经网络的并行训练：</p>
<p><img src="/archives/2932556/image-20200729203114640.png" alt="image-20200729203114640" style="zoom: 80%;"></p>
<p>[Seide et al., 2014<a href="#refer-anchor-5"><sup>5</sup></a>]提出了一种1-bit表示各个节点计算梯度。和常规的方法相比，它得到了10倍的加速比。[Strom, 2015<a href="#refer-anchor-6"><sup>6</sup></a>]作者提出了一种阈值量化方法。提前选定一个阈值，如果梯度大于这个阈值就量化为<span class="math inline">\(+1\)</span>，如果小于这个阈值就量化为<span class="math inline">\(0\)</span>。[Alistarh et al., 2016<a href="#refer-anchor-7"><sup>7</sup></a>]提出了QSGD方法，允许每个节点在精度、梯度和模型的精度之间进行权衡。QSGD利用随机四舍五入的思想将梯度量化为一组离散值，并利用无损编码产生高效的编码。[Dryden et al., 2016<a href="#refer-anchor-8"><sup>8</sup></a>]]作者提出一种简单的自适应量化方法来选择合适的梯度进行量化并发送。</p>
<p>[Wen et al., 2017<a href="#refer-anchor-9"><sup>9</sup></a>]]通过提出了TernGrad解决了并行过程中水平扩展的问题。他将梯度量化为<span class="math inline">\(\{-1,0,1\}\)</span>。在发送给中心参数服务器之前，每个梯度都将被如下量化： <span class="math display">\[
\tilde{\Delta}_{t}=\operatorname{ternarize}\left(\Delta_{t}\right)=s_{t} \cdot \operatorname{sign}\left(\Delta_{t}\right) \circ b_{t}
\]</span> 其中<span class="math inline">\(s_{t}=\max \left(\operatorname{abs}\left(\Delta_{t}\right)\right)\)</span>，其中<span class="math inline">\(\circ\)</span>是<a href="https://www.baidu.com/link?url=w-LVD0IIl4PbHY-Vzc-UEKgvX7_8m_uRUWXH56DVxRjY77fZbsptVsF2pO7Gmxx3cRBReXg7sz3JTvIakfzCprx8m2RSMUNzT_E2Ppx3wyfA6RMWuAA7E66zF4btnsYK&amp;wd=&amp;eqid=8509435200010e68000000055f216602" target="_blank" rel="noopener external nofollow noreferrer">哈达玛积</a>，<span class="math inline">\(b_t\)</span>是遵循如下伯努利分布的随机二进制向量： <span class="math display">\[
\left\{\begin{array}{l}
P\left(b_{t k}=1 \mid \Delta_{t}\right)=\left|\Delta_{t k}\right| / s_{t} \\
P\left(b_{t k}=0 \mid \Delta_{t}\right)=1-\left|\Delta_{t k}\right| / s_{t}
\end{array}\right.
\]</span> 采用这种方法，服务器和工作节点之间的通信开销可以降低接近20倍.</p>
<p>在单一节点的环境中，我们也能够通过量化梯度获得益处。为了减小反向传播的计算开销，[Rastegari et al., 2016<a href="#refer-anchor-11"><sup>11</sup></a>]将梯度量化为2-bits来进行高性能通信。[Zhou et al., 2016<a href="#refer-anchor-10"><sup>10</sup></a>]他还量化了反向传播过程中的梯度。他们发现使用随机四舍五入的方法是非常重要的，使量程梯度工作得很好。他们设计了如下的k比特量化函数， <span class="math display">\[
\tilde{f}_{\gamma}^{k}(d r)=2 \max _{0}(|d r|)\left[\text { quantize }_{k}\left(\frac{d r}{2 \max _{0}(|d r|)+\frac{1}{2}}\right)-\frac{1}{2}\right]
\]</span> 其中<span class="math inline">\(d r=\frac{\partial c}{\partial r}\)</span>是在某些层输出<span class="math inline">\(r\)</span>的梯度，<span class="math inline">\(quantize_k\)</span>被用于量化一个实数输入<span class="math inline">\(r_{i} \in[0,1]\)</span>到k-bit输出值<span class="math inline">\(r_{0} \in[0,1]\)</span>， <span class="math display">\[
r_{o}=\frac{1}{2^{k}-1} \operatorname{round}\left(\left(2^{k}-1\right) r_{i}\right)
\]</span> 他们还在训练过程中加入额外的噪声，以弥补量化造成的准确性损失。</p>
<h5 id="挑战-3">挑战</h5>
<ul>
<li><p>梯度的大小和符号对于更新权重都很重要。为了量化梯度，我们必须解决如何将这两个因素纳入计算的问题。</p></li>
<li><p>一种简单的量化梯度的方法可能在实践中并不奏效，因为它可能违反随机梯度下降算法的收敛条件。在这种情况下需要更复杂的方法。</p></li>
</ul>
<div id="refer-anchor-1">

</div>
<ul>
<li>[1] <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener external nofollow noreferrer">Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Advances in neural information processing systems. 2012: 1097-1105.</a>
<div id="refer-anchor-2">

</div></li>
<li>[2] <a href="https://arxiv.org/pdf/1409.1556" target="_blank" rel="noopener external nofollow noreferrer">Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.</a>
<div id="refer-anchor-3">

</div></li>
<li>[3] <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Szegedy_Going_Deeper_With_2015_CVPR_paper.html" target="_blank" rel="noopener external nofollow noreferrer">Szegedy C, Liu W, Jia Y, et al. Going deeper with convolutions[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 1-9.</a>
<div id="refer-anchor-4">

</div></li>
<li>[4] <a href="https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html" target="_blank" rel="noopener external nofollow noreferrer">He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 770-778.</a>
<div id="refer-anchor-5">

</div></li>
<li>[5] <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/IS140694.pdf" target="_blank" rel="noopener external nofollow noreferrer">Seide F, Fu H, Droppo J, et al. 1-bit stochastic gradient descent and its application to data-parallel distributed training of speech dnns[C]//Fifteenth Annual Conference of the International Speech Communication Association. 2014.</a>
<div id="refer-anchor-6">

</div></li>
<li>[6] <a href="http://papers.nips.cc/paper/6768-qsgd-communication-efficient-sgd-via-gradient-quantization-and-encoding.pdf" target="_blank" rel="noopener external nofollow noreferrer">Alistarh D, Grubic D, Li J, et al. QSGD: Communication-efficient SGD via gradient quantization and encoding[C]//Advances in Neural Information Processing Systems. 2017: 1709-1720.</a>
<div id="refer-anchor-7">

</div></li>
<li>[7] <a href="https://www.isca-speech.org/archive/interspeech_2015/i15_1488.html" target="_blank" rel="noopener external nofollow noreferrer">Strom N. Scalable distributed DNN training using commodity GPU cloud computing[C]//Sixteenth Annual Conference of the International Speech Communication Association. 2015.</a>
<div id="refer-anchor-8">

</div></li>
<li>[8] <a href="https://ieeexplore.ieee.org/abstract/document/7835789/" target="_blank" rel="noopener external nofollow noreferrer">Dryden N, Moon T, Jacobs S A, et al. Communication quantization for data-parallel training of deep neural networks[C]//2016 2nd Workshop on Machine Learning in HPC Environments (MLHPC). IEEE, 2016: 1-8.</a>
<div id="refer-anchor-9">

</div></li>
<li>[9] <a href="http://papers.nips.cc/paper/6749-terngrad-ternary-gradients-to-reduce-communication-in-distributed-deep-learning.pdf" target="_blank" rel="noopener external nofollow noreferrer">Wen W, Xu C, Yan F, et al. Terngrad: Ternary gradients to reduce communication in distributed deep learning[C]//Advances in neural information processing systems. 2017: 1509-1519.</a>
<div id="refer-anchor-10">

</div></li>
<li>[10] <a href="https://arxiv.org/pdf/1606.06160" target="_blank" rel="noopener external nofollow noreferrer">Zhou S, Wu Y, Ni Z, et al. Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients[J]. arXiv preprint arXiv:1606.06160, 2016.</a>
<div id="refer-anchor-11">

</div></li>
<li>[11] <a href="https://link.springer.com/chapter/10.1007/978-3-319-46493-0_32" target="_blank" rel="noopener external nofollow noreferrer">Rastegari M, Ordonez V, Redmon J, et al. Xnor-net: Imagenet classification using binary convolutional neural networks[C]//European conference on computer vision. Springer, Cham, 2016: 525-542.</a></li>
</ul>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/fcc7e450.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/fcc7e450.html" class="post-title-link" itemprop="url">Error Compensated Quantized SGD and its Applications to Large-scale</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-28 14:55:28" itemprop="dateCreated datePublished" datetime="2020-07-28T14:55:28+08:00">2020-07-28</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-11 13:45:42" itemprop="dateModified" datetime="2020-10-11T13:45:42+08:00">2020-10-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">分布式机器学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%9A%E4%BF%A1%E4%BC%98%E5%8C%96/" itemprop="url" rel="index"><span itemprop="name">通信优化</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%9A%E4%BF%A1%E4%BC%98%E5%8C%96/%E6%A2%AF%E5%BA%A6%E5%8E%8B%E7%BC%A9/" itemprop="url" rel="index"><span itemprop="name">梯度压缩</span></a>
                </span>
            </span>

          
            <span id="/archives/fcc7e450.html" class="post-meta-item leancloud_visitors" data-flag-title="Error Compensated Quantized SGD and its Applications to Large-scale" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/fcc7e450.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/fcc7e450.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>6 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="摘要">摘要</h2>
<p>本文提出了一种错误补偿的随机梯度量化方法来提高训练效率。量化本地梯度来减小通信负担，但是累积的量化误差会影响收敛的速度。此外，本文对收敛行为进行了理论分析，并证明了其相对于其他算法的优势。实验表明该算法能够再不降级影响收敛性能的情况下，将梯度压缩两个数量级。</p>
<h2 id="介绍">介绍</h2>
<p>一些方法注重将梯度量化为固定值，这样可以用更少的bits来进行通信传输（Zhou et al 2016<a href="#refer-anchor-1"><sup>1</sup></a>）；还有更加激进的方法，比如二进制或者三元组的表达（Seide et al., 2014<a href="#refer-anchor-2"><sup>2</sup></a>;Strom, 2015<a href="#refer-anchor-3"><sup>3</sup></a>; Wen et al., 2017<a href="#refer-anchor-4"><sup>4</sup></a>）；其他方法是在通信的过程中进行稀疏化，其中，每次迭代只有梯度的一小部分在节点之间通信传输（Wangni et al., 2017<a href="#refer-anchor-5"><sup>5</sup></a>; Lin et al., 2018<a href="#refer-anchor-6"><sup>6</sup></a>）</p>
<p>本文提出了误差补偿随机梯度量化方法，称为EC-SGD。该算法和<span class="math inline">\(1Bits\)</span>算法<a href="#refer-anchor-2"><sup>2</sup></a>不太相同，它将之前量化的所有梯度误差都考虑在内，并不只是使用最新一轮的量化误差。</p>
<p>在（Alistarh et al., 2017<a href="#refer-anchor-8"><sup>8</sup></a>）中，作者证明了所提出的QSGD算法达到某次最优间隙所需的迭代次数与随机量化梯度的方差界成正比。然而这不能够解释我们方法的收敛行为，因为我们量化梯度是有偏估计，并不像QSGD那样。事实上，量化梯度的方差边界比在QSGD当中的更大，因为量化误差的累计会更大。为了解决这个问题，我们从另一个角度给出了收敛性分析，并且证明了我们的算法比QSGD算法有着更加严格的最坏情况的错误边界。结果表明，我们提出的误差反馈方案可以很好地抑制量化误差对误差界的影响，我们在实验中观察到，与QSGD相比，次最优性间隙更小。</p>
<h2 id="相关工作">相关工作</h2>
<h3 id="异步sgd">异步SGD</h3>
<p>Hogwild!（Recht et al. 2011）（其他工作相对来说时间比较久远，这里就不罗列了）</p>
<h3 id="梯度量化">梯度量化</h3>
<p>（Seide et al., 2014<a href="#refer-anchor-2"><sup>2</sup></a>）<span class="math inline">\(1Bit-SGD\)</span>用于对梯度的量化，将<span class="math inline">\(0\)</span>作为阈值，量化为<span class="math inline">\(1\)</span>或者<span class="math inline">\(-1\)</span>。在量化过程中引入上一轮的量化误差作为反馈。相似的想法在（Strom, 2015<a href="#refer-anchor-3"><sup>3</sup></a>）中被采纳，它通过迭代累计局部梯度并且仅传输超过预先选择的阈值的梯度分量。（Wen et al., 2017<a href="#refer-anchor-4"><sup>4</sup></a>）扩展了这一想法，并且将梯度压缩至了三元组来保证其无偏性。QSGD（Alistarh et al., 2017<a href="#refer-anchor-8"><sup>8</sup></a>）采用均匀分布的方式随机量化梯度，更加细致地分析其收敛性。ZipML（Zhang et al., 2017<a href="#refer-anchor-8"><sup>8</sup></a>）介绍了一种优化的量化策略，在分布式状态下动态选择量化节点。（Zhou et al 2016<a href="#refer-anchor-1"><sup>1</sup></a>）提出了DoReFa-Net来训练卷积神经网络，将输入、权重和梯度都进行定点的量化。</p>
<h3 id="梯度稀疏化">梯度稀疏化</h3>
<p>梯度丢弃方法是由（Aji &amp; Heafield, 2017<a href="#refer-anchor-10"><sup>10</sup></a>）将稀疏化方法引入到梯度当中，来减小通信误差。在（Wangni et al., 2017<a href="#refer-anchor-11"><sup>11</sup></a>）将梯度量化抽象成了线性规划问题，目的就是最小化量化梯度的方差增长。（Lin et al., 2018<a href="#refer-anchor-6"><sup>6</sup></a>）提出了深度梯度压缩算法，利用动量校正，梯度剪裁，动量因子掩饰，热身训练，以实现更高的稀疏性而不失去准确性。</p>
<h2 id="preliminaries">Preliminaries</h2>
<p>（比较容易理解，暂时不翻译）</p>
<h2 id="误差压缩量化sgd方法">误差压缩量化SGD方法</h2>
<p>在每一轮迭代，之前每一轮的累计的量化误差都会对当前本地梯度进行补偿，再通过随机量化函数进行压缩。</p>
<p>令<span class="math inline">\(Q: \mathbb{R}^{d} \rightarrow \mathcal{C}^{d}\)</span>是一个无偏的随机量化函数，它将每部分的<span class="math inline">\(d\)</span>个维度向量映射到量化密码本<span class="math inline">\(\mathcal{C}\)</span>中。密码本通常只包含有限数量的元素，因此量化向量能够高效的编码。在每次迭代中，每个节点在广播之前量化他们的本地梯度： <span class="math display">\[
\tilde{\mathbf{g}}_{p}^{(t)}=Q\left(\mathbf{g}_{p}^{(t)}\right)
\]</span> 其中<span class="math inline">\(\mathbf{g}_{p}^{(t)}\)</span>是第<span class="math inline">\(p\)</span>个节点和第<span class="math inline">\(t\)</span>次迭代的本地梯度，<span class="math inline">\(\tilde{\mathbf{g}}_{p}^{(t)}\)</span>表示他的量化产物。</p>
<p>当节点接收到所有从其他节点发送过来的本地梯度之后，它将计算全局梯度以及更新它本地的模型，采用以下式子： <span class="math display">\[
\mathbf{w}^{(t+1)}=\mathbf{w}^{(t)}-\eta \cdot \tilde{\mathbf{g}}^{(t)}=\mathbf{w}^{(t)}-\frac{\eta}{P} \sum_{p=1}^{P} \tilde{\mathbf{g}}_{p}^{(t)}
\]</span></p>
<p>其中<span class="math inline">\(\eta&gt;0\)</span>表示学习率。</p>
<p>ECQ-SGD的核心思想是当量化本地梯度时，当前梯度和之前累加的量化误差都会考虑在内。特别的，我们使用<span class="math inline">\(\mathbf{h}_{p}^{(t)}\)</span>代表第<span class="math inline">\(p\)</span>个节点的第<span class="math inline">\(t\)</span>次迭代的累计量化误差： <span class="math display">\[
\mathbf{h}_{p}^{(t)}=\sum_{t^{\prime}=0}^{t-1} \beta^{t-1-t^{\prime}}\left(\mathbf{g}_{p}^{\left(t^{\prime}\right)}-\tilde{\mathbf{g}}_{p}^{\left(t^{\prime}\right)}\right)
\]</span> 其中<span class="math inline">\(\beta\)</span>是时间减弱因子。注意到累计量化误差的更新式如下： <span class="math display">\[
\mathbf{h}_{p}^{(t)}=\beta \mathbf{h}_{p}^{(t-1)}+\left(\mathbf{g}_{p}^{(t-1)}-\tilde{\mathbf{g}}_{p}^{(t-1)}\right)
\]</span> 其中<span class="math inline">\(\mathbf{h}_{p}^{(0)}=\mathbf{0}\)</span>。量化本地梯度将会通过量化函数计算出误差补偿梯度： <span class="math display">\[
\tilde{\mathbf{g}}_{p}^{(t)}=Q\left(\mathbf{g}_{p}^{(t)}+\alpha \mathbf{h}_{p}^{(t)}\right)
\]</span> 其中<span class="math inline">\(\alpha\)</span>代表补偿系数。</p>
<p>这里我们采用服从均匀分布的随机量化函数，类似于QSGD算法（Alistarh et al., 2017<a href="#refer-anchor-8"><sup>8</sup></a>），其中第<span class="math inline">\(i\)</span>个维度将会量化为： <span class="math display">\[
\tilde{g}_{i}=\|\mathbf{g}\| \cdot \operatorname{sgn}\left(g_{i}\right) \cdot \xi\left(\left|g_{i}\right| ;\|\mathbf{g}\|\right)
\]</span> 其中$|| <span class="math inline">\(表示扩展因子（可以选择\)</span>l_2<span class="math inline">\(或者\)</span>l_{}<span class="math inline">\(这两种方式），\)</span>()<span class="math inline">\(是随机函数，是映射到如下元素中\)</span>{0, , , 1}$： <span class="math display">\[
\xi\left(\left|g_{i}\right| ;\|\mathbf{g}\|\right)=\left\{\begin{array}{ll}
\frac{l}{s}, &amp; \text { with probability } l+1-s \cdot \frac{\left|g_{i}\right|}{\|\mathbf{g}\|} \\
\frac{l+1}{s}, &amp; \text { otherwise }
\end{array}\right.
\]</span> 其中<span class="math inline">\(\left|g_{i}\right| /\|\mathbf{g}\|\)</span>是落在<span class="math inline">\(\left[\frac{l}{s}, \frac{l+1}{s}\right)\)</span>范围之内。超参数<span class="math inline">\(s\)</span>表示非零量化等级：更大的<span class="math inline">\(s\)</span>会导致更加细粒度的量化，同时导致更多的通信消耗。我们采用<span class="math inline">\(Q_{s}(\cdot)\)</span>代表量化函数，<span class="math inline">\(s\)</span>表示非零量化等级。</p>
<p>在量化之后，我们只需要使用<span class="math inline">\(r=\left\lceil\log _{2}(2 s+1)\right\rceil\)</span>bits来编码每个梯度<span class="math inline">\(\tilde{g}_{i}\)</span>，一个完整的精度表示扩展因子$ ||$。全部的通信需要花费<span class="math inline">\(32+d\)</span>bits（<span class="math inline">\(r \ll 32\)</span>）,原始的梯度需要每个维度32-bit的全精度来表示。更加有效的编码模式，例如Huffman编码，能够进一步地减小通信量。令<span class="math inline">\(d_k\)</span>表示分配各<span class="math inline">\(k\)</span>个量化级别的维数，之后整个编码长度最多只需要<span class="math inline">\(\sum_{k=1}^{2 s+1} d_{k} \log _{2} \frac{d}{d_{k}}\)</span>个bits。</p>
<p>算法1概括了上述的整个过程：</p>
<p><img src="/archives/fcc7e450/image-20200728190425444.png" alt="image-20200728190425444" style="zoom:67%;"></p>
<h2 id="理论分析">理论分析</h2>
<p>（暂时省略）</p>
<h2 id="实验分析">实验分析</h2>
<h3 id="线性模型">线性模型</h3>
<p>使用三个人造数据集：Syn-256、Syn-512和Syn-1024。每个数据集包含10k个训练样本，后缀表示特征维度<span class="math inline">\(d\)</span>。训练样本通过<span class="math inline">\(y_{i}=\mathbf{w}^{* T} \mathbf{x}_{i}+\epsilon_{i}\)</span>生成，其中<span class="math inline">\(\mathbf{w}^{*} \in \mathbb{R}^{d}\)</span>是我们希望获得的潜在模型参数，<span class="math inline">\(\left\{\epsilon_{i}\right\}\)</span>是服从独立同分布的随机噪声。学习率是0.02，QSGD和ECQ-SGD都采用<span class="math inline">\(l_2\)</span>作为扩展因子，采用<span class="math inline">\(4\)</span>作为量化等级。</p>
<p>下图我们比较了损失函数值（上方）和距离最优解的距离（下方）。对于这三个数据集，ECQ-SGD损失函数的收敛性更加接近于<span class="math inline">\(32-bit\)</span>全精度的SGD算法，比<span class="math inline">\(QSGD\)</span>的训练速度明显更快。另一方面，QSGD(或ECQ-SGD)与32Bit-FP在最优解距离上的差距度量了量化误差对(21)中定义的误差界的贡献。ECQ-SGD的距离差明显小于QSGD，说明量化误差对误差界的贡献得到了很好的抑制。</p>
<p>下面我们比较了在大数据集上，QSGD和ECQ-SGD运行时训练速率，Syn-20k，它包括了50k训练样本和20k维度的特征。在图三中，我们多维度展示了在1k轮迭代之后各种方法的时间消耗和测试误差。我们发现ECQ-SGD达到和32Bit-FP相似的测试误差，比32Bit-FP和QSGD所用的时间更短。虽然ECQ-SGD需要额外的编码好解码时间，由于通信量的降低，整个训练速度依然得到了提高：</p>
<p><img src="/archives/fcc7e450/image-20200728192202073.png" alt="image-20200728192202073" style="zoom:67%;"></p>
<p>其次，本文还对两个公开的数据集<code>YearPredictionMSD</code>（回归）和<code>gisette</code>分类。在不同的量化方法下对这两个数据集的逻辑回归和线性回归做了测评：</p>
<p><img src="/archives/fcc7e450/image-20200728192421592.png" alt="image-20200728192421592" style="zoom: 80%;"></p>
<h3 id="卷积神经网络">卷积神经网络</h3>
<p>本文还在卷积神经网络上做了测试。CIFAR-10和ResNet-20模型，采用不同的量化方法，结果如图所示：</p>
<figure>
<img src="/archives/fcc7e450/image-20200728192625094.png" alt="image-20200728192625094"><figcaption aria-hidden="true">image-20200728192625094</figcaption>
</figure>
<p>在第一列中，比较了各种方法的整体通信负担和损失函数值的情况。与32位全精度基准方法相比，每个模型的超参数被分离，以达到可以忽略的精度损失。我们发现所有的方法都以相似的速度收敛，但ECQ-SGD在通信成本上降低了80倍以上，并且显著优于其他梯度量化方法。</p>
<p>在第二列和第三列中，我们比较了它和QSGD的细节，因为它和我们的方法最为相关。我们采用了不同的扩展因子：第二列是<span class="math inline">\(l_2\)</span>，第三列是<span class="math inline">\(l_{\infty}\)</span>。我们发现我们观察到，ECQ-SGD在收敛速度和分类精度方面始终优于QSGD，而在相同的超参数设置下，这两种方法在降低通信成本方面是相似的。</p>
<h3 id="性能模型">性能模型</h3>
<p>我们采用（Yan et al., 2015）提出的性能评估模型对ECQ-SGD算法进行评估。对计算量和通信时间进行轻量级分析，以估计较大集群的学习效率。主要硬件规格如下:Intel Xeon E5-2680 CPU, Nvidia Tesla P40 GPU(每个节点8个单元)，Mellanox ConnectX-3 Pro网卡(40Gb/s连通性)。</p>
<p>下图中，我们展示了采用ResNet-50模型训练ILSVRC-12数据集。训练512个GPU，ECQ-SGD先比于普通的SGD达到了143.5%的加速比。</p>
<p><img src="/archives/fcc7e450/image-20200728193508865.png" alt="image-20200728193508865" style="zoom:67%;"></p>
<h2 id="结论">结论</h2>
<p>为了提高大规模分布式优化的学习效率，本文提出了误差补偿量化SGD算法。通过引入误差反馈机制，ECQ-SGD算法可以有效地抑制量化误差对误差界的贡献。我们从理论的角度分析了它的收敛行为，并证明了它比最先进的QSGD算法的优势。在线性模型和非凸卷积神经网络上的实验证明了该算法的有效性。</p>
<h2 id="部分参考文献">部分参考文献</h2>
<div id="refer-anchor-1">

</div>
<ul>
<li>[1] <a href="https://arxiv.org/pdf/1606.06160" target="_blank" rel="noopener external nofollow noreferrer">Zhou S, Wu Y, Ni Z, et al. Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients[J]. arXiv preprint arXiv:1606.06160, 2016.</a></li>
</ul>
<div id="refer-anchor-2">

</div>
<ul>
<li>[2] <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/IS140694.pdf" target="_blank" rel="noopener external nofollow noreferrer">Seide F, Fu H, Droppo J, et al. 1-bit stochastic gradient descent and its application to data-parallel distributed training of speech dnns[C]//Fifteenth Annual Conference of the International Speech Communication Association. 2014.</a></li>
</ul>
<div id="refer-anchor-3">

</div>
<ul>
<li>[3] <a href="https://www.isca-speech.org/archive/interspeech_2015/papers/i15_1488.pdf" target="_blank" rel="noopener external nofollow noreferrer">Strom N. Scalable distributed DNN training using commodity GPU cloud computing[C]//Sixteenth Annual Conference of the International Speech Communication Association. 2015.</a>
<div id="refer-anchor-4">

</div></li>
<li>[4] <a href="http://papers.nips.cc/paper/6749-terngrad-ternary-gradients-to-reduce-communication-in-distributed-deep-learning.pdf" target="_blank" rel="noopener external nofollow noreferrer">Wen W, Xu C, Yan F, et al. Terngrad: Ternary gradients to reduce communication in distributed deep learning[C]//Advances in neural information processing systems. 2017: 1509-1519.</a>
<div id="refer-anchor-5">

</div></li>
<li>[5] <a href="http://papers.nips.cc/paper/7405-gradient-sparsification-for-communication-efficient-distributed-optimization.pdf" target="_blank" rel="noopener external nofollow noreferrer">Wangni J, Wang J, Liu J, et al. Gradient sparsification for communication-efficient distributed optimization[C]//Advances in Neural Information Processing Systems. 2018: 1299-1309.</a>
<div id="refer-anchor-6">

</div></li>
<li>[6] <a href="https://arxiv.org/pdf/1712.01887" target="_blank" rel="noopener external nofollow noreferrer">Lin Y, Han S, Mao H, et al. Deep gradient compression: Reducing the communication bandwidth for distributed training[J]. arXiv preprint arXiv:1712.01887, 2017.</a>
<div id="refer-anchor-7">

</div></li>
<li>[7] <a href="http://papers.nips.cc/paper/4390-hogwild-a-lock-free-approach-to-parallelizing-stochastic-gradient-descent.pdf" target="_blank" rel="noopener external nofollow noreferrer">Recht B, Re C, Wright S, et al. Hogwild: A lock-free approach to parallelizing stochastic gradient descent[C]//Advances in neural information processing systems. 2011: 693-701.</a>
<div id="refer-anchor-8">

</div></li>
<li>[8] <a href="http://papers.nips.cc/paper/6768-qsgd-communication-efficient-sgd-via-gradient-quantization-and-encoding.pdf" target="_blank" rel="noopener external nofollow noreferrer">Alistarh D, Grubic D, Li J, et al. QSGD: Communication-efficient SGD via gradient quantization and encoding[C]//Advances in Neural Information Processing Systems. 2017: 1709-1720.</a>
<div id="refer-anchor-9">

</div></li>
<li>[9] <a href="http://proceedings.mlr.press/v70/zhang17e.html" target="_blank" rel="noopener external nofollow noreferrer">Zhang H, Li J, Kara K, et al. ZipML: Training linear models with end-to-end low precision, and a little bit of deep learning[C]//International Conference on Machine Learning. 2017: 4035-4043.</a>
<div id="refer-anchor-10">

</div></li>
<li>[10] <a href="https://arxiv.org/pdf/1704.05021" target="_blank" rel="noopener external nofollow noreferrer">Aji A F, Heafield K. Sparse communication for distributed gradient descent[J]. arXiv preprint arXiv:1704.05021, 2017.</a>
<div id="refer-anchor-11">

</div></li>
<li>[11] <a href="http://papers.nips.cc/paper/7405-gradient-sparsification-for-communication-efficient-distributed-optimization.pdf" target="_blank" rel="noopener external nofollow noreferrer">Wangni J, Wang J, Liu J, et al. Gradient sparsification for communication-efficient distributed optimization[C]//Advances in Neural Information Processing Systems. 2018: 1299-1309.</a>
<div id="refer-anchor-12">

</div></li>
</ul>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/d06ef2e3.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/d06ef2e3.html" class="post-title-link" itemprop="url">QSGD Communication-Efficient SGD via Gradient Quantization and Encoding</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-28 09:06:20" itemprop="dateCreated datePublished" datetime="2020-07-28T09:06:20+08:00">2020-07-28</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-11 13:45:49" itemprop="dateModified" datetime="2020-10-11T13:45:49+08:00">2020-10-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">分布式机器学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%9A%E4%BF%A1%E4%BC%98%E5%8C%96/" itemprop="url" rel="index"><span itemprop="name">通信优化</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%9A%E4%BF%A1%E4%BC%98%E5%8C%96/%E6%A2%AF%E5%BA%A6%E5%8E%8B%E7%BC%A9/" itemprop="url" rel="index"><span itemprop="name">梯度压缩</span></a>
                </span>
            </span>

          
            <span id="/archives/d06ef2e3.html" class="post-meta-item leancloud_visitors" data-flag-title="QSGD Communication-Efficient SGD via Gradient Quantization and Encoding" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/d06ef2e3.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/d06ef2e3.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>3.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="摘要">摘要</h2>
<p>本文提出了量化SGD（QSGD）方法，可以帮助使用者平滑地权衡通信带宽和收敛时间：在方差成本可能较高的情况下，节点可以调节每轮迭代发送的比特数。本文证明了这种权衡是内在的，某种意义上，提高它超过某个阈值将违反信息理论的下界。QSGD保证了在凸和非凸目标函数上的收敛性，在异步条件下，能够使用随机方差减小的方法进行拓展。</p>
<h2 id="简介">简介</h2>
<p>比较流行的减少通信量通常采用有损压缩的方法<a href="#refer-anchor-1"><sup>1</sup></a><a href="#refer-anchor-2"><sup>2</sup></a><a href="#refer-anchor-3"><sup>3</sup></a>。一种方式是简单地降低表示精度，在凸和稀疏的条件下证明了收敛性<a href="#refer-anchor-4"><sup>4</sup></a>。<span class="math inline">\(1BitSGD\)</span>量化方法为梯度的量化压缩奠定了基础。</p>
<h3 id="本文贡献">本文贡献</h3>
<p>本文重点关注数据并行SGD算法的通信开销和收敛速率保证。我们提出有损的梯度压缩方法：QSGD算法，它可以在每一次迭代中在通信量和方差之间做平衡。</p>
<p>QSGD建立在两种算法思想上。第一种是直观的随机量化模式：在某进程中给出一个梯度向量，我们通过四舍五入到一组离散的值来量化每个部分，有原则地保持原始数据的统计性质。第二种是量化梯度的有效无损代码，利用他们的统计属性来生成有效的编码。我们分析给出了QSGD引起的精度-方差权衡的严格界限。</p>
<p>QSGD非常普遍，在假设条件下，对于非凸目标和异步迭代，能够收敛到局部最小。在非平凡扩展的情况下，我们创新了一种随机方差减小的QSGD算法，称为QSVRG，它具有指数级的收敛速率。</p>
<p>一个关键的问题是QSGD的压缩方差平衡是否是固有的：例如，任何算法保证最多恒定方差放大每次迭代需要传输<span class="math inline">\(\Omega(n)\)</span>bits。回答是肯定的：在此基础上的渐近改进将打破分布式平均估计的通信复杂度下限（不是很懂这块内容）。</p>
<p>与1BitSGD相比，QSGD具有渐近高压缩性能，在标准假设下可证明收敛性，在某些情况下具有较好的实际性能。</p>
<h2 id="preliminaries">Preliminaries</h2>
<p>（暂时省略）</p>
<h2 id="量化随机梯度下降qsgd">量化随机梯度下降（QSGD）</h2>
<h3 id="一般性的随机量化和编码">一般性的随机量化和编码</h3>
<h4 id="随机量化">随机量化</h4>
<p>我们现在思考随机梯度向量一般参数有损压缩方案。压缩函数用<span class="math inline">\(Q_s(v)\)</span>表示，其中<span class="math inline">\(s \geq 1\)</span>调节参数，代表我们所要实现的量化的程度。直观上来看，我们定义<span class="math inline">\(s\)</span>服从<span class="math inline">\(0-1\)</span>的均匀分布，每个值都以一种保持预期值并引入最小方差的方式进行量化，例如下图：</p>
<p><img src="/archives/d06ef2e3/image-20200728104606218.png" alt="image-20200728104606218" style="zoom:67%;"></p>
<p>上图是5级的广义随机量化的示例</p>
<p>对于任意的<span class="math inline">\(\boldsymbol{v} \in \mathbb{R}^{n} \text { with } \boldsymbol{v} \neq \mathbf{0})\)</span>，<span class="math inline">\(Q_{s}(\boldsymbol{v})\)</span>定义如下： <span class="math display">\[
Q_{s}\left(v_{i}\right)=\|\boldsymbol{v}\|_{2} \cdot \operatorname{sgn}\left(v_{i}\right) \cdot \xi_{i}(\boldsymbol{v}, s)
\]</span> 其中<span class="math inline">\(\xi_{i}(\boldsymbol{v}, s)\)</span>是一个独立随机变量，定义如下。令<span class="math inline">\(0 \leq \ell&lt;s\)</span>是一个整数，例如<span class="math inline">\(\left|v_{i}\right| /\|\boldsymbol{v}\|_{2} \in[\ell / s,(\ell+1) / s]\)</span>。<span class="math inline">\([\ell / s,(\ell+1) / s]\)</span>是与$|v_{i}| /||_{2} $相符的量化间隔。定义： <span class="math display">\[
\xi_{i}(\boldsymbol{v}, s)=\left\{\begin{array}{ll}
\ell / s &amp; \text { 以如下概率 } 1-p\left(\frac{\left|v_{i}\right|}{\|\boldsymbol{v}\|_{2}}, s\right) \\
(\ell+1) / s &amp; \text { 其他情况. }
\end{array}\right.
\]</span> 这里<span class="math inline">\(p(a, s)=a s-\ell\)</span>对于任何的<span class="math inline">\(a \in[0,1]\)</span>。如果<span class="math inline">\(v=0\)</span>，我们定义<span class="math inline">\(Q(v,s)=0\)</span>。</p>
<p><span class="math inline">\(\xi_{i}(\boldsymbol{v}, s)\)</span>的分布具有最小的方差，它的期望满足<span class="math inline">\(\mathbb{E}\left[\xi_{i}(\boldsymbol{v}, s)\right]=\left|v_{i}\right| /\|\boldsymbol{v}\|_{2}\)</span>。我们可以证明如下：</p>
<p><strong>引理</strong> 对于任意<span class="math inline">\(\boldsymbol{v} \in \mathbb{R}^{n}\)</span>，我们有（1）<span class="math inline">\(\mathbb{E}\left[Q_{s}(\boldsymbol{v})\right]=\boldsymbol{v} \text { (无偏) }\)</span>；（2）<span class="math inline">\(\mathbb{E}\left[\left\|Q_{s}(\boldsymbol{v})-\boldsymbol{v}\right\|_{2}^{2}\right] \leq \min \left(n / s^{2}, \sqrt{n} / s\right)\|\boldsymbol{v}\|_{2}^{2}\)</span>（方差最小边界）；（3）<span class="math inline">\(\mathbb{E}\left[\left\|Q_{s}(\boldsymbol{v})\right\|_{0}\right] \leq s(s+\sqrt{n})\)</span>稀疏性</p>
<h4 id="梯度的高效编码">梯度的高效编码</h4>
<p>对于任意的向量<span class="math inline">\(v\)</span>，输出<span class="math inline">\(Q_s(v)\)</span>可以表达为三元组<span class="math inline">\(\left(\|v\|_{2}, \sigma, \zeta\right)\)</span>，其中<span class="math inline">\(\sigma\)</span>是向量中<span class="math inline">\(v_i\)</span>的符号，<span class="math inline">\(\zeta\)</span>是整数<span class="math inline">\(s \cdot \xi_{i}(\boldsymbol{v}, s)\)</span>的向量。我们可以发现，大的整数出现的频率很低。我们将通过专门的<code>Eilias</code>整数编码来利用这一点。</p>
<p>直觉上，对于任何正整数<span class="math inline">\(k\)</span>，他的编码用<span class="math inline">\(Elias(k)\)</span>表示<span class="math inline">\(k\)</span>的二进制，并且在它的前面加上长度表示。然后递归地编码这个前缀。我们发现对于任何整数<span class="math inline">\(k\)</span>，结果编码的长度为<span class="math inline">\(\operatorname{Elias}(k) \mid=\log k+\log \log k+\ldots+1 \leq(1+o(1)) \log k+1\)</span>。编码和解码过程非常高效。</p>
<p>给定的梯度向量可以表示为三元组<span class="math inline">\(\left(\|\boldsymbol{v}\|_{2}, \boldsymbol{\sigma}, \boldsymbol{\zeta}\right)\)</span>，具有<span class="math inline">\(s\)</span>压缩等级，我们的编码输出为字符串<span class="math inline">\(S\)</span>，定义如下：第一使用<span class="math inline">\(32bits\)</span>编码<span class="math inline">\(\|\boldsymbol{v}\|_{2}\)</span>。它继续使用<span class="math inline">\(Elias\)</span>递归编码读第一个非零项<span class="math inline">\(\boldsymbol{\zeta}\)</span>的位置进行编码。接下来附加一个bit代表<span class="math inline">\(\boldsymbol{\sigma}_i\)</span>，遵循<span class="math inline">\(s \cdot \xi_{i}(\boldsymbol{v}, s)\)</span>。迭代进行，它继续从当前的写入坐标到下一个非零的距离，并以同样的方式对坐标的<span class="math inline">\(\boldsymbol{\sigma}_i\)</span>和<span class="math inline">\(\boldsymbol{\zeta}_i\)</span>进行编码。解码方案很简单：我们首先读取<span class="math inline">\(32bits\)</span>来构建<span class="math inline">\(\|\boldsymbol{v}\|_{2}\)</span>，接下来，迭代使用<span class="math inline">\(Elias\)</span>递归编码的译码方案读取非零项<span class="math inline">\(\boldsymbol{\zeta}\)</span>和<span class="math inline">\(\boldsymbol{\sigma}\)</span>的位置和值。</p>
<div id="refer-anchor-1">

</div>
<ul>
<li>[1] <a href="http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf" target="_blank" rel="noopener external nofollow noreferrer">Dean J, Corrado G, Monga R, et al. Large scale distributed deep networks[C]//Advances in neural information processing systems. 2012: 1223-1231.</a>
<div id="refer-anchor-2">

</div></li>
<li>[2] <a href="https://arxiv.org/pdf/1603.04467.pdf" target="_blank" rel="noopener external nofollow noreferrer">Abadi M, Agarwal A, Barham P, et al. Tensorflow: Large-scale machine learning on heterogeneous distributed systems[J]. arXiv preprint arXiv:1603.04467, 2016.</a>
<div id="refer-anchor-3">

</div></li>
<li>[3] <a href="http://papers.nips.cc/paper/6749-terngrad-ternary-gradients-to-reduce-communication-in-distributed-deep-learning.pdf" target="_blank" rel="noopener external nofollow noreferrer">Wen W, Xu C, Yan F, et al. Terngrad: Ternary gradients to reduce communication in distributed deep learning[C]//Advances in neural information processing systems. 2017: 1509-1519.</a>
<div id="refer-anchor-4">

</div></li>
<li>[4] <a href="http://papers.nips.cc/paper/5717-taming-the-wild-a-unified-analysis-of-hogwild-style-algorithms.pdf" target="_blank" rel="noopener external nofollow noreferrer">De Sa C M, Zhang C, Olukotun K, et al. Taming the wild: A unified analysis of hogwild-style algorithms[C]//Advances in neural information processing systems. 2015: 2674-2682.</a></li>
</ul>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/487a2936.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/487a2936.html" class="post-title-link" itemprop="url">粉笔公考-判断推理-图形推理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-27 20:39:49" itemprop="dateCreated datePublished" datetime="2020-07-27T20:39:49+08:00">2020-07-27</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-11 13:45:27" itemprop="dateModified" datetime="2020-10-11T13:45:27+08:00">2020-10-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%AC%E5%8A%A1%E5%91%98%E8%80%83%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">公务员考试</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%AC%E5%8A%A1%E5%91%98%E8%80%83%E8%AF%95/%E5%88%A4%E6%96%AD%E6%8E%A8%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">判断推理</span></a>
                </span>
            </span>

          
            <span id="/archives/487a2936.html" class="post-meta-item leancloud_visitors" data-flag-title="粉笔公考-判断推理-图形推理" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/487a2936.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/487a2936.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>851</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="判断推理题型">判断推理题型</h2>
<ul>
<li>图形推理</li>
<li>类比推理</li>
<li>定义判断</li>
<li>逻辑判断</li>
</ul>
<h2 id="图形推理">图形推理</h2>
<h3 id="命题形式">命题形式</h3>
<h4 id="一组图">一组图</h4>
<p>大多数：从左到右整体去看</p>
<p>有时候：跳着看，考地相对较少</p>
<p><img src="/archives/487a2936/image-20200727205210815.png" alt="image-20200727205210815" style="zoom:67%;"></p>
<h4 id="两组图">两组图</h4>
<p>第一组用于找规律，第二组用规律（模仿第一组的规律即可，细节变化以第二组图为准）</p>
<p><img src="/archives/487a2936/image-20200727205147584.png" alt="image-20200727205147584" style="zoom:67%;"></p>
<h4 id="九宫格">九宫格</h4>
<p>优先横着看，其次再是竖着看（很少斜着、S型和米子型）</p>
<h4 id="分组分类">分组分类</h4>
<p>一般分成两组，在组内找出各自的规律（找出两个规律）</p>
<p><img src="/archives/487a2936/image-20200727205400400.png" alt="image-20200727205400400" style="zoom:67%;"></p>
<h4 id="空间类折纸盒">空间类：折纸盒</h4>
<p>六面体为主，转化成平面</p>
<p><img src="/archives/487a2936/image-20200727205533123.png" alt="image-20200727205533123" style="zoom:67%;"></p>
<h5 id="特殊题型">特殊题型</h5>
<ul>
<li>截面图</li>
<li>三视图</li>
<li>立体拼合</li>
</ul>
<h2 id="六大规律">六大规律</h2>
<p>重点通过识别图形特征，来识别考察什么规律</p>
<ol type="1">
<li>位置规律</li>
<li>样式规律</li>
<li>属性规律</li>
<li>特殊规律</li>
<li>数量规律</li>
<li>空间规律</li>
</ol>
<h3 id="位置规律">位置规律</h3>
<h4 id="特征">特征</h4>
<p>位置类识别特征：各图元素组成相同</p>
<p><img src="/archives/487a2936/image-20200727210022937.png" alt="image-20200727210022937" style="zoom:67%;"></p>
<h4 id="考点">考点</h4>
<ul>
<li>平移</li>
<li>旋转、翻转（常结合考察）</li>
</ul>
<h5 id="考点一平移">考点一：平移</h5>
<ol type="1">
<li><p>方向：直线（上下、左右、对角线）、绕圈（顺/逆时针）</p>
<p><img src="/archives/487a2936/image-20200727210259617.png" alt="image-20200727210259617" style="zoom:67%;"></p></li>
<li><p>步数：恒定、递增（等差）、周期（考的少）</p></li>
</ol>
<h6 id="宫格形黑块平移">宫格形黑块平移</h6>
<ol type="1">
<li>个别黑块重合
<ul>
<li>题干和选项大部分元素组成完全一致，个别一两副图少黑块</li>
<li>题干第一幅图的黑块一般不会重合</li>
</ul></li>
</ol>
<p><img src="/archives/487a2936/image-20200727210936304.png" alt="image-20200727210936304" style="zoom:67%;"></p>
<ol start="2" type="1">
<li><p>黑块走到头后</p>
<ul>
<li><p>循环走：从头开始</p>
<p><img src="/archives/487a2936/image-20200727211118319.png" alt="image-20200727211118319" style="zoom:67%;"></p></li>
<li><p>折返走：直接弹回</p>
<p><img src="/archives/487a2936/image-20200727211135729.png" alt="image-20200727211135729" style="zoom:67%;"></p></li>
<li><p>“双胞胎”黑块如何分辨：就近走原则</p>
<p><img src="/archives/487a2936/image-20200727211331662.png" alt="image-20200727211331662" style="zoom:67%;"></p></li>
</ul></li>
</ol>
<h6 id="多宫格方向判定">多宫格方向判定</h6>
<p>题型特征：16宫格图形多个黑块平移</p>
<ol type="1">
<li><p>直线走：</p>
<ul>
<li>横行黑块数量相同（左右走）</li>
<li>竖行黑块数量相同（上下走）</li>
</ul>
<p><img src="/archives/487a2936/image-20200727211823656.png" alt="image-20200727211823656" style="zoom:67%;"></p></li>
<li><p>绕圈走：</p>
<ul>
<li>中间颜色数量相同，有限考虑内外圈分开看</li>
</ul>
<p><img src="/archives/487a2936/image-20200727212331968.png" alt="image-20200727212331968" style="zoom:67%;"></p></li>
</ol>
<h5 id="考点二旋转与翻转">考点二：旋转与翻转</h5>
<h6 id="旋转">旋转</h6>
<ol type="1">
<li>方向：顺时针、逆时针</li>
<li>常见角度：45°、60°、90°、180°等</li>
</ol>
<blockquote>
<p>TIPS：难题可以采用两两相邻比较</p>
<p>钟表类：麦面一个框，中间有一个点，饶了一圈线——常考旋转</p>
</blockquote>
<h6 id="翻转">翻转</h6>
<ol type="1">
<li>左右翻转</li>
<li>上下翻转（可能存在视觉误差，需要警觉）</li>
</ol>
<blockquote>
<p>TIPS：先看容易看懂的</p>
</blockquote>
<p>这道题目需要注意上下翻转，很难看出来（第二张图到第三张图）</p>
<p><img src="/archives/487a2936/image-20200727214018551.png" alt="image-20200727214018551" style="zoom:67%;"></p>
<h6 id="区分旋转和翻转">区分旋转和翻转</h6>
<ul>
<li><p>只有左右互换（上下不变）——左右翻</p>
<p><img src="/archives/487a2936/image-20200727214319546.png" alt="image-20200727214319546" style="zoom:67%;"></p></li>
<li><p>只有上下互换（左右不变）——上下翻</p>
<p><img src="/archives/487a2936/image-20200727214353319.png" alt="image-20200727214353319" style="zoom:67%;"></p></li>
<li><p>上下、左右都互换——旋转180°</p>
<p><img src="/archives/487a2936/image-20200727214429063.png" alt="image-20200727214429063" style="zoom:67%;"></p></li>
</ul>
<h3 id="样式规律">样式规律</h3>
<h4 id="特征-1">特征</h4>
<p>样式识别特征：元素组成相似</p>
<h4 id="考点-1">考点</h4>
<ol type="1">
<li>遍历</li>
<li>加减同异</li>
<li>黑白运算</li>
</ol>
<h5 id="考点一遍历">考点一：遍历</h5>
<p>图形特征：小元素重复出现</p>
<p>解题思路：缺啥补啥（遍历包括空白/阴影等很多方面）</p>
<p><img src="/archives/487a2936/image-20200727215015137.png" alt="image-20200727215015137" style="zoom:67%;"></p>
<h5 id="考点二加减同异"><strong>考点二：加减同异</strong></h5>
<p>识别特征：相同线条重复出现</p>
<ol type="1">
<li>相加、相减</li>
<li>求异（保留不同）</li>
<li>求同（保留相同）</li>
</ol>
<blockquote>
<p>对比选项，从特殊线条入手（横线、竖线、最长最短线）</p>
</blockquote>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
    

            <ul class="sidebar-nav motion-element">
              <li class="sidebar-nav-toc">
                文章目录
              </li>
              <li class="sidebar-nav-overview">
                站点概览
              </li>
            </ul>
    



      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Jiyang"
      src="/img/avatar.jpg">
  <p class="site-author-name" itemprop="name">Jiyang</p>
  <div class="site-description" itemprop="description">世界上有两样东西不可直视，一是太阳，二是人心</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">24</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/wjykl22" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;wjykl22" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:wjykl22@gmail.com" title="E-Mail → mailto:wjykl22@gmail.com" rel="noopener external nofollow noreferrer" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



    <div class="links-of-blogroll motion-element links-of-blogroll-block">
      <div class="links-of-blogroll-title">
        <!-- modify icon to fire by szw -->
        <i class="fa fa-history fa-" aria-hidden="true"></i>
        近期文章
      </div>
      <ul class="links-of-blogroll-list">
        
        
          <li>
            <a href="/archives/5c29dc6b.html" title="AccPar: Tensor Partitioning for Heterogeneous Deep Learning Accelerators" target="_blank">AccPar: Tensor Partitioning for Heterogeneous Deep Learning Accelerators</a>
          </li>
        
          <li>
            <a href="/archives/740c8dcf.html" title="Alpha策略" target="_blank">Alpha策略</a>
          </li>
        
          <li>
            <a href="/archives/40cbe9ff.html" title="Device Placement Optimization with Reinforcement Learning" target="_blank">Device Placement Optimization with Reinforcement Learning</a>
          </li>
        
          <li>
            <a href="/archives/60fdd68b.html" title="Communication Optimal Parallel Multiplication of Sparse Random Matrices" target="_blank">Communication Optimal Parallel Multiplication of Sparse Random Matrices</a>
          </li>
        
          <li>
            <a href="/archives/62b3642.html" title="Beyond Data and Model Parallelism for Deep Neural Networks" target="_blank">Beyond Data and Model Parallelism for Deep Neural Networks</a>
          </li>
        
      </ul>
    </div>



        <!--网易云音乐-->
        <div id="music163player">
        	<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=110 src="//music.163.com/outchain/player?type=0&id=5283780459&auto=1&height=90"></iframe>
        	</iframe>
        </div>
        	  <!--/网易云音乐-->

      </div>
      <div style="">
  <canvas id="canvas" style="width:60%;">当前浏览器不支持canvas，请更换浏览器后再试</canvas>
</div>
<script>
(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*更新时钟*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //时间发生变化
            if(NewData[i] !== data[i]){
                //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //增加小球
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*渲染*/
    function render(){
        //重置画布宽度，达到清空画布的效果
        canvas.height = 100;
        //渲染时钟
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //渲染小球
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //更新时钟
        updateDigitTime();
        //更新小球状态
        updateBalls();
        //渲染
        render();
    },50);
}

})();
</script>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-eye"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jiyang</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">264k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">4:01</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener external nofollow noreferrer" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener external nofollow noreferrer" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_lines.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : true,
      appId      : 'owd5pfJvVjoBkwE0F3w7Oqc5-gzGzoHsz',
      appKey     : 'pQbK5JId2AmEfxG3oSiFXAFP',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>
<div class="moon-menu">
  <div class="moon-menu-items">
    
    <div class="moon-menu-item" onclick="back2bottom()">
      <svg aria-hidden="true" focusable="false" data-prefix="fa" data-icon="chevron-down" class="svg-inline--fa fa-chevron-down fa-w-14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"></path></svg>    </div>
    
    <div class="moon-menu-item" onclick="back2top()">
      <svg aria-hidden="true" focusable="false" data-prefix="fa" data-icon="chevron-up" class="svg-inline--fa fa-chevron-up fa-w-14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M240.971 130.524l194.343 194.343c9.373 9.373 9.373 24.569 0 33.941l-22.667 22.667c-9.357 9.357-24.522 9.375-33.901.04L224 227.495 69.255 381.516c-9.379 9.335-24.544 9.317-33.901-.04l-22.667-22.667c-9.373-9.373-9.373-24.569 0-33.941L207.03 130.525c9.372-9.373 24.568-9.373 33.941-.001z"></path></svg>    </div>
    
  </div>
  <div class="moon-menu-button" onclick="moonMenuClick()">
    <svg class="moon-menu-svg">
      <circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle>
      <circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle>
      <g class="moon-menu-points">
        <circle class="moon-menu-point" r=".2rem" cx="0" cy="-.8rem"></circle>
        <circle class="moon-menu-point" r=".2rem"></circle>
        <circle class="moon-menu-point" r=".2rem" cx="0" cy=".8rem"></circle>
      </g>
    </svg>
    <div class="moon-menu-icon">
    </div>
    <div class="moon-menu-text">
    </div>
  </div>
</div>
<script src="/js/injector.js"></script>
</body>
</html>
