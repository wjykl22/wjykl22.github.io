<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
<meta name="baidu-site-verification" content="code-oCEdExorFr" />
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="fW8TTOKkJ22AYrbkjIZSXK1q7VYmUdGIjhfdDJ_2-9k">
  <meta name="msvalidate.01" content="true">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=EB Garamond:300,300italic,400,400italic,700,700italic|Cinzel Decorative:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-loading-bar.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"wjykl22.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":300,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
<meta property="og:type" content="website">
<meta property="og:title" content="韭零后">
<meta property="og:url" content="https://wjykl22.github.io/index.html">
<meta property="og:site_name" content="韭零后">
<meta property="og:description" content="世界上有两样东西不可直视，一是太阳，二是人心">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Jiyang">
<meta property="article:tag" content="keywords">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://wjykl22.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>
<link rel="stylesheet" type="text/css" href="/css/injector.css" />
  <title>韭零后</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="韭零后" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">韭零后</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">公元1996 - ?</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-主页">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>主页</a>

  </li>
        <li class="menu-item menu-item-关于">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-标签">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-目录">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>目录</a>

  </li>
        <li class="menu-item menu-item-结构">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>结构</a>

  </li>
        <li class="menu-item menu-item-站点地图">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
        <li class="menu-item menu-item-公益">

    <a href="/404.html" rel="section"><i class="fa fa-heartbeat fa-fw"></i>公益</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/5c29dc6b.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/5c29dc6b.html" class="post-title-link" itemprop="url">AccPar: Tensor Partitioning for Heterogeneous Deep Learning Accelerators</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-10-07 10:33:24" itemprop="dateCreated datePublished" datetime="2020-10-07T10:33:24+08:00">2020-10-07</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-11 13:46:29" itemprop="dateModified" datetime="2020-10-11T13:46:29+08:00">2020-10-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">分布式机器学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文阅读笔记</span></a>
                </span>
            </span>

          
            <span id="/archives/5c29dc6b.html" class="post-meta-item leancloud_visitors" data-flag-title="AccPar: Tensor Partitioning for Heterogeneous Deep Learning Accelerators" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/5c29dc6b.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/5c29dc6b.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="accpar针对异构深度学习加速器的张量划分方法">AccPar：针对异构深度学习加速器的张量划分方法</h2>
<ul>
<li>作者：Linghao Song 南加利福尼亚大学 杜克大学</li>
<li>IEEE HPCA（High Performance Computer Architecture）</li>
</ul>
<h3 id="概括">概括</h3>
<p>提出了AccPar，在异构加速阵列上划分张量的方法，和其他方法相比，AccPar有着更加完备的张量划分空间（tensor partition space）同时能够产生其他方法未知的并行策略。</p>
<p>AccPar依赖于异构环境下，计算和通信消耗（computation and communication costs）。而且AccPar可以根据加速器的异构情况，使用灵活的划分比率来适应异构环境。</p>
<p>相比于OWT（one weird trick）方法、HYPAR方法以及传统的数据并行方法，分别提升了2.98倍、3.78倍和6.30倍。</p>
<h3 id="背景介绍">背景介绍</h3>
<h5 id="现有方法">现有方法</h5>
<h6 id="one-weird-trickowt">One Weird Trick（OWT）</h6>
<p>对于卷积层采用数据并行，对于全连接层采用模型并行</p>
<h6 id="hypar">HYPAR</h6>
<p>提出了一种最小化数据通信的并行方法，能够比OWT拥有更好的效果。</p>
<p>这些方法存在如下问题：</p>
<ol type="1">
<li>并行方法的搜索基于不完备的设计空间</li>
<li>只能处理线性结构的DNN体系结构</li>
<li>它们只考虑了通信而没有考虑计算</li>
<li>假设是在设备同构的环境下</li>
</ol>
<h5 id="accpar方法">AccPar方法</h5>
<ol type="1">
<li>提出了完备的张量划分空间
<ul>
<li>批量（batch size）</li>
<li>数据数据尺寸（imput data size）</li>
<li>输出数据尺寸（output data size）</li>
</ul></li>
<li>提出了异构环境下communication cost和computation cost</li>
<li>灵活变化划分比率</li>
</ol>
<blockquote>
<p>总的来说，该方法能够感知计算资源的异构性和网络带宽能力，从而实现张量的划分。</p>
</blockquote>
<p>作者先对现有DNN加速器和加速框架和它们不同的细分领域做了梳理：</p>
<figure>
<img src="/archives/5c29dc6b/image-20201007185047869.png" alt="image-20201007185047869"><figcaption aria-hidden="true">image-20201007185047869</figcaption>
</figure>
<blockquote>
<p>包括FPGA加速、数据流处理（Dataflow）、PIM（Processing-in-memory）以及其他新型的并行框架</p>
</blockquote>
<h3 id="张量划分空间">张量划分空间</h3>
<ul>
<li>批量（batch size）</li>
<li>数据数据尺寸（imput data size）</li>
<li>输出数据尺寸（output data size）</li>
</ul>
<p>符号简要介绍：</p>
<table>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\mathbf{F}_{l}\)</span></td>
<td>输入到第<span class="math inline">\(l\)</span>层的特征矩阵（第<span class="math inline">\(l-1\)</span>层输出的特征向量）</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathbf{E}_{l-1}\)</span></td>
<td>输入到第<span class="math inline">\(l\)</span>层的误差矩阵（第<span class="math inline">\(l+1\)</span>层输出的误差矩阵）</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathbf{W}_{l}\)</span></td>
<td>第<span class="math inline">\(l\)</span>层的参数</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\triangle \mathbf{W}_{l}\)</span></td>
<td>第<span class="math inline">\(l\)</span>层的梯度</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(B\)</span></td>
<td>Mini-batch size</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathbf{D}_{i,l}\)</span></td>
<td>第<span class="math inline">\(l\)</span>层输入数据尺寸</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathbf{D}_{0,l}\)</span></td>
<td>第<span class="math inline">\(l\)</span>层输出数据尺寸</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\alpha, \beta\)</span></td>
<td>划分比率</td>
</tr>
</tbody>
</table>
<h4 id="问题阐述">问题阐述</h4>
<p>一个DNN网络涉及下列三个重要环节：</p>
<ol type="1">
<li>前传：Forward <span class="math inline">\(\mathbf{F}_{l+1}=f\left(\mathbf{F}_{l} \times \mathbf{W}_{l}\right)\)</span></li>
<li>后传：Backward <span class="math inline">\(\mathbf{E}_{l}=\left(\mathbf{E}_{l+1} \times \mathbf{W}_{l}^{\top}\right) \odot f^{\prime}\left(\mathbf{F}_{l}\right)\)</span></li>
<li>求梯度：Gradient <span class="math inline">\(\Delta \mathbf{W}_{l}=\mathbf{F}_{l}^{\top} \times \mathbf{E}_{l+1}\)</span></li>
</ol>
<p>用数据尺寸可表示为：</p>
<ol type="1">
<li>前传：Forward <span class="math inline">\(\left(B, D_{o, l}\right) \leftarrow\left(B, D_{i, l}\right) \times\left(D_{i, l}, D_{o, l}\right)\)</span></li>
<li>后传：Backward <span class="math inline">\(\left(B, D_{i, l}\right) \leftarrow\left(B, D_{o, l}\right) \times\left(D_{o, l}, D_{i, l}\right)\)</span></li>
<li>求梯度：Gradient <span class="math inline">\(\left(D_{i, l}, D_{o, l}\right) \leftarrow\left(D_{i, l}, B\right) \times\left(B, D_{o, l}\right)\)</span></li>
</ol>
<h4 id="划分维度">划分维度</h4>
<p>假设1：<span class="math inline">\(\mathbf{F}_{l}\)</span>和<span class="math inline">\(\mathbf{E}_{l}\)</span>采用相同的划分方式</p>
<blockquote>
<p>原因：如果采用不相同的划分方式，会导致引入额外的通信，这和最小化communication costs相悖。</p>
</blockquote>
<p>假设2：这几个维度并不是独立的，所以每次只有一个维度能够划分</p>
<blockquote>
<p>举例：以前传：Forward为例<span class="math inline">\(\left(B, D_{o, l}\right) \leftarrow\left(B, D_{i, l}\right) \times\left(D_{i, l}, D_{o, l}\right)\)</span>，如果我们选定要划分<span class="math inline">\(B\)</span>这个维度</p>
<ol type="1">
<li>其中<span class="math inline">\(\mathbf{D}_{i,l}\)</span>不能划分，如果划分了矩阵乘法就无法进行了。</li>
<li><span class="math inline">\(D_{o, l}\)</span>也不能划分，如果划分，最后得到的矩阵只有左上右下或者右上左下的部分矩阵计算</li>
</ol>
</blockquote>
<p>以下内容只以Type-1作为例子进行详细阐述，其余的划分方法原理相同。（假设两块加速卡）</p>
<h5 id="type-1划分b维度">Type-1：划分B维度</h5>
<h6 id="前传forward">前传：Forward</h6>
<p><span class="math display">\[
\mathbf{F}_{l+1}[b, q o]=\sum_{q i \in\left\{1, \cdots, D_{i, l}\right\}} \mathbf{F}_{l}[b, q i] \times \mathbf{W}_{l}[q i, q o]
\]</span></p>
<p>其中一块数据划分<span class="math inline">\(\mathbf{F}_{l}[1: \alpha B,:]\)</span>，另一块<span class="math inline">\(\mathbf{F}_{l}[\alpha B+1: B,:]\)</span></p>
<figure>
<img src="/archives/5c29dc6b/image-20201007191707379.png" alt="image-20201007191707379"><figcaption aria-hidden="true">image-20201007191707379</figcaption>
</figure>
<h6 id="后传backward">后传：Backward</h6>
<p><span class="math display">\[
\mathbf{E}_{l}[b, q i]=\sum_{q o \in\left\{1, \cdots, D_{o, l}\right\}} \mathbf{E}_{l+1}[b, q o] \times \mathbf{W}_{l}^{\top}[q o, q i]
\]</span></p>
<p>其中一块误差划分<span class="math inline">\(\mathbf{E}_{l+1}[1: \alpha B,:]\)</span>，另一块：<span class="math inline">\(\mathbf{E}_{l}[\alpha B+1: B,:]\)</span></p>
<figure>
<img src="/archives/5c29dc6b/image-20201007191855397.png" alt="image-20201007191855397"><figcaption aria-hidden="true">image-20201007191855397</figcaption>
</figure>
<h6 id="梯度计算">梯度计算</h6>
<p><span class="math display">\[
\Delta \mathbf{W}_{l}[q i, q o]=\sum_{b \in\{1, \cdots, B\}} \mathbf{F}_{l}^{\top}[q i, b] \times \mathbf{E}_{l+1}[b, q o]
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\Delta \mathbf{W}_{l}[q i, q o]=&amp; \sum_{b \in\{1, \cdots, \alpha B\}} \mathbf{F}_{l}^{\top}[q i, b] \times \mathbf{E}_{l+1}[b, q o] \\
&amp;+\sum_{b \in\{\alpha B+1, \cdots, B\}} \mathbf{F}_{l}^{\top}[q i, b] \times \mathbf{E}_{l+1}[b, q o]
\end{aligned}
\]</span></p>
<figure>
<img src="/archives/5c29dc6b/image-20201007192005535.png" alt="image-20201007192005535"><figcaption aria-hidden="true">image-20201007192005535</figcaption>
</figure>
<blockquote>
<p>这里将产生层内通信（intra-layer），因为最后的结果必须将两块加速卡上计算出的部分梯度相加得到梯度结果。</p>
</blockquote>
<h5 id="type-2划分mathbfd_il维度">Type-2：划分<span class="math inline">\(\mathbf{D}_{i,l}\)</span>维度</h5>
<p>同样的分析方式，只不过划分<span class="math inline">\(\mathbf{D}_{i,l}\)</span>维度的层内（intra-layer）通信是在前传：Forward过程中产生，因为： <span class="math display">\[
\begin{aligned}
\mathbf{F}_{l+1}[b, q o]=&amp; \sum_{q i \in\left\{1, \cdots, \alpha D_{i, l}\right\}} \mathbf{F}_{l}[b, q i] \times \mathbf{W}_{l}[q i, q o] \\
&amp;+\sum_{q i \in\left\{\alpha D_{i, l}+1, \cdots, D_{i, l}\right\}} \mathbf{F}_{l}[b, q i] \times \mathbf{W}_{l}[q i, q o]
\end{aligned}
\]</span></p>
<h5 id="type-3划分mathbfd_ol维度">Type-3：划分<span class="math inline">\(\mathbf{D}_{o,l}\)</span>维度</h5>
<p>在后传：Backward的过程中产生层内（intra-layer）通信 <span class="math display">\[
\begin{aligned}
\mathbf{E}_{l}[b, q i] &amp;=\sum_{q o \in\left\{1, \cdots, \alpha D_{o, l}\right\}} \mathbf{E}_{l+1}[b, q o] \times \mathbf{W}_{l}^{\top}[q o, q i] \\
&amp;+\sum_{q o \in\left\{\alpha D_{o, l}+1, \cdots, D_{o, l}\right\}} \mathbf{E}_{l+1}[b, q o] \times \mathbf{W}_{l}^{\top}[q o, q i]
\end{aligned}
\]</span></p>
<h4 id="和hypar以及owt对比">和Hypar以及OWT对比</h4>
<p>OWT是特殊的数据和模型并行</p>
<p>HyPar是不完备的搜索空间，只考虑了Type-1和Type-2</p>
<h3 id="accpar的cost-model">AccPar的COST MODEL</h3>
<h5 id="communication-cost-model">Communication Cost Model</h5>
<p><span class="math display">\[
E_{\mathrm{cm}}=\frac{\mathbb{A}(\mathbf{T})}{b_{i}}
\]</span></p>
<p><span class="math inline">\(\mathbb{A}(\mathbf{T})\)</span>是虽有维度的长度，例如：shape是（2,2,4,4）的张量，其<span class="math inline">\(\mathbb{A}(\mathbf{T})\)</span>就是为<span class="math inline">\(2*2*4*4\)</span>，<span class="math inline">\(b_i\)</span>代表加速器<span class="math inline">\(i\)</span>的带宽。</p>
<h6 id="层内通信intra-layer">层内通信（Intra-layer）</h6>
<p>以Type-1中的梯度计算为例：如果划分比例是<span class="math inline">\(\alpha\)</span>；</p>
<p>对于每个<span class="math inline">\(b \in\{1, \cdots, \alpha B\}\)</span>，都有<span class="math inline">\(\mathbb{A}\left(\mathbf{F}_{l}^{\top}[:, b] \times \mathbf{E}_{l+1}[b,:]\right)=D_{i, l} \cdot D_{o, l}=\mathbb{A}\left(\triangle \mathbf{W}_{l}\right)=\mathbb{A}\left(\mathbf{W}_{l}\right)\)</span></p>
<h6 id="层间通信inter-layer">层间通信（Inter-layer）</h6>
<p>总共有Type1-3种划分方式，这一层到下一层排列组合就有9种层间通信的方式，举例来说：</p>
<figure>
<img src="/archives/5c29dc6b/image-20201007193609409.png" alt="image-20201007193609409"><figcaption aria-hidden="true">image-20201007193609409</figcaption>
</figure>
<ol type="1">
<li><p>（a）Type1 到 2；（f）Type2 到 3 以及 （h）Type 3 到 2</p>
<p>层间的通信为0，由于从<span class="math inline">\(l\)</span>（绿）到<span class="math inline">\(l+1\)</span>层（蓝）的划分是完全相同的，所以不需要额外的通信。</p></li>
<li><p>（c）Type1 到 3；（d）Type2 到 1；（e）Type 2 到 2 以及（i）Type 3 到 3</p>
<p>以（c）图为例，在前传的过程中，加速器<span class="math inline">\(i\)</span>的划分比率是<span class="math inline">\(\alpha\)</span>，它具有绿色阴影部分的张量，但是下一层这个加速器采用Type4的划分方式，需要完整的蓝色的张量，他们之间相差了黑色部分，需要进行通信，该通信称为层间通信，<span class="math inline">\((\beta B) \times D_{o, l}=\beta \mathbb{A}\left(\mathbf{F}_{l+1}\right)\)</span>。</p></li>
<li><p>（b）Type1 到 2；（g）Type3 到 1</p>
<p>同理，此处不再赘述。</p></li>
</ol>
<h5 id="computation-cost-model">Computation Cost Model</h5>
<p><span class="math display">\[
E_{\mathrm{cp}}=\frac{\alpha \cdot \mathbb{C}\left(\mathbf{T}_{1} \times \mathbf{T}_{2}\right)}{c_{i}}
\]</span></p>
<p>分子是划分后张量所需的精度位数（bits），分母是加速器计算密度（tensor computation density）</p>
<p>并不难理解</p>
<blockquote>
<p>以上都是以全连接层举例的，同样的可以扩展到卷积层，只不过卷积层采用4维的张量进行表示，分析方法相同，此处不再赘述。</p>
</blockquote>
<h3 id="accpar的划分算法">AccPar的划分算法</h3>
<p>采用动态规划的方法，采用递归定义的方式，定义第<span class="math inline">\(L_i\)</span>层的累计cost，公式如下： <span class="math display">\[
c\left(L_{i+1}, t\right)=\min _{t t \in \mathscr{T}}\left\{c\left(L_{i}, t t\right)+E_{\mathrm{cp}}(t)+E_{\mathrm{cm}}(t t, t)\right\}
\]</span> 其中<span class="math inline">\(t \in \mathscr{T}=\{\text { Type-I, Type-II, Type-III }\}\)</span>，<span class="math inline">\(E_{\mathrm{cp}}(t)\)</span>表示当前层<span class="math inline">\(L_{i+1}\)</span>采用<span class="math inline">\(t\)</span>这种划分方式产生的computation cost，<span class="math inline">\(E_{\mathrm{cm}}(t t, t)\)</span>表示层间和层内的cost和。</p>
<p>最小化通信代价和计算代价即可</p>
<figure>
<img src="/archives/5c29dc6b/image-20201007195435976.png" alt="image-20201007195435976"><figcaption aria-hidden="true">image-20201007195435976</figcaption>
</figure>
<p>对于每个基本的分区类型，在算法执行期间，我们需要记录到前一层的路径，以便在遍历所有层之后回溯，如图中的黑色箭头所示。</p>
<h4 id="划分比率">划分比率</h4>
<p>划分比率是为了适用异构环境下的加速阵列，基本思路是使得两个加速器通信和计算时间尽量接近，以缩短同步等待时间，因此可以采用如下方法： <span class="math display">\[
\begin{array}{r}
\alpha \cdot E_{\mathrm{cp}}\left(p_{i, l}\right)+\alpha \cdot E_{\mathrm{cm}}\left(p_{i, l}\right) \\
=\beta \cdot E_{\mathrm{cp}}\left(p_{j, l}\right)+\beta \cdot E_{\mathrm{cm}}\left(p_{j, l}\right)
\end{array}
\]</span></p>
<h3 id="实验">实验</h3>
<p>主要和数据并行、OWT以及HyPar进行加速比的对比实验，如下图所示：</p>
<ul>
<li><p>同构</p>
<figure>
<img src="/archives/5c29dc6b/image-20201007195855700.png" alt="image-20201007195855700"><figcaption aria-hidden="true">image-20201007195855700</figcaption>
</figure></li>
<li><p>异构</p>
<figure>
<img src="/archives/5c29dc6b/image-20201007195910275.png" alt="image-20201007195910275"><figcaption aria-hidden="true">image-20201007195910275</figcaption>
</figure></li>
</ul>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/740c8dcf.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/740c8dcf.html" class="post-title-link" itemprop="url">Alpha策略</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-09-22 19:35:06" itemprop="dateCreated datePublished" datetime="2020-09-22T19:35:06+08:00">2020-09-22</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-09-29 18:41:40" itemprop="dateModified" datetime="2020-09-29T18:41:40+08:00">2020-09-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/" itemprop="url" rel="index"><span itemprop="name">投资</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84/" itemprop="url" rel="index"><span itemprop="name">量化投资</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8A%95%E8%B5%84/%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84/Alpha%E7%AD%96%E7%95%A5/" itemprop="url" rel="index"><span itemprop="name">Alpha策略</span></a>
                </span>
            </span>

          
            <span id="/archives/740c8dcf.html" class="post-meta-item leancloud_visitors" data-flag-title="Alpha策略" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/740c8dcf.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/740c8dcf.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>0</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/40cbe9ff.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/40cbe9ff.html" class="post-title-link" itemprop="url">Device Placement Optimization with Reinforcement Learning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-09-10 14:27:49" itemprop="dateCreated datePublished" datetime="2020-09-10T14:27:49+08:00">2020-09-10</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-09 09:16:04" itemprop="dateModified" datetime="2020-10-09T09:16:04+08:00">2020-10-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">分布式机器学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文阅读笔记</span></a>
                </span>
            </span>

          
            <span id="/archives/40cbe9ff.html" class="post-meta-item leancloud_visitors" data-flag-title="Device Placement Optimization with Reinforcement Learning" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/40cbe9ff.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/40cbe9ff.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li><p>题目：使用强化学习方法进行设备Placement</p>
<p>英文：<a href="https://arxiv.org/abs/1706.04972" target="_blank" rel="noopener external nofollow noreferrer">Device Placement Optimization with Reinforcement Learning</a> ACM</p></li>
<li><p>作者Azalia Mirhoseini</p></li>
</ul>
<h2 id="摘要">摘要</h2>
<p>将神经网络模型的不同部分放置在不同设备上进行分布式训练的决策问题，通常是由专业人员主观设计。本文提出了一种方法，能够优化Tensorflow计算图模型在不同设备上的配置，解决该问的关键是采用序列到序列（Seq2Seq）的模型来预测TensorFlow图模型应该运行在哪个可用设备上，在预测设备上的执行时间作为反馈信号更新序列到序列的模型参数。</p>
<p>该方法在Inception-V3模型的Image-Net分类上做了实验，在RNN LSTM上对语言模型和机器翻译做了测试，并找到了重要的设备配置方案，这些方案要比人工划分配置有着更好的性能表现。</p>
<h2 id="介绍">介绍</h2>
<p>改模型如下图所示，简单的说就是系统自动进行一系列的性能试验，考虑各种环境因素，最终得到模型的那个部分应该安排在哪个设备上进行训练，同时优化通信效率。改模型的关键是采用Seq2Seq模型，读取操作的有关信息和他们之间的关联。每一个提议都会在硬件环境下执行并测算执行时间，执行时间作为反馈信号更新序列到序列的模型参数。</p>
<h2 id="相关工作">相关工作</h2>
<p>文章首先介绍了强化学习在系统性能优化上的一些工作，包括[Mao et al., 2016]提出的采用策略梯度进行资管调度管理的优化方法。这类方法需要依赖回报的手工目标函数的期望值，而本文直接优化配置的运行时间，减去了设计中间成本模型所需的时间。</p>
<p>其次介绍了图分割的相关应用，利用谱分析和图的矩阵表示进行划分。图划分算法可以应用于计算图的划分，但是计算非常昂贵，原因在于为了应用这些算法，需要为图构建代价模型，这样的模型构建要模拟各种情况，非常昂贵，并不现实。</p>
<p>一种非常著名的开源图划分算法是Scotch优化方法（Pellegrini 2009），该方法作为本论文的基准测试。Scotch试图在一组连接的处理节点之间平衡任务集合的计算负载，同时通过在附近的节点上保持密集的通信任务来降低通信成本。</p>
<p>该方法需要两个图，第一张图被称为目标架构图，它的顶点表示硬件资源，例如CPU或者GPU，它们的边表示可用的通信路径，例如PCIe总线和网络通信。第二张图是源图，它将计算映射到目标架构图进行建模。在TensorFlow的实例中，程序的计算被建模成图，改图的顶点表示操作，边表示他们之间的张量通信。Scotch用户必须选择如何以及何时图应该划分。然而，本篇论文的实验中，依赖于Scotch中软件的默认策略实现，这些策略已经被广泛调整过了。</p>
<h2 id="框架方法">框架方法</h2>
<p>思考TensorFlow的计算图<span class="math inline">\(\mathcal{G}\)</span> ，它是由M个操作<span class="math inline">\(\left\{O_{1}, O_{2}, \ldots, O_{M}\right\}\)</span>以及一系列<span class="math inline">\(D\)</span>个可用设备资源组成。配置方法 <span class="math inline">\(\mathcal{P}=\left\{p_{1}, p_{2}, \ldots, p_{M}\right\}\)</span>是将操作 <span class="math inline">\(o_{i} \in \mathcal{G}\)</span>分配到设备<span class="math inline">\(p_i\)</span>，其中<span class="math inline">\(p_{i} \in\{1, \ldots, D\}\)</span>。令<span class="math inline">\(r(\mathcal{P})\)</span>表示完整执行<span class="math inline">\(\mathcal{P}\)</span>配置下计算图<span class="math inline">\(\mathcal{G}\)</span>所需要的花费的时间。我们的目标是找到<span class="math inline">\(\mathcal{P}\)</span>使得<span class="math inline">\(r(\mathcal{P})\)</span>最小。</p>
<p>如果直接对<span class="math inline">\(r(\mathcal{P})\)</span>并不是很合适，存在如下两个问题：（1）刚开始训练的时候，由于不好的采样，导致<span class="math inline">\(r(\mathcal{P})\)</span>会有很多噪音，导致不好的学习信号；（2）快要达到瘦脸之后，采样变得非常相似，微笑的变化导致学习信号的可识别性比较差。所以这里采用<span class="math inline">\(R(\mathcal{P})=\sqrt{r(\mathcal{P})}\)</span>代替，鲁棒性更好。</p>
<p>首先是该方法的整体框架</p>
<p><img src="/archives/40cbe9ff/image-20200910171246846.png" alt="image-20200910171246846" style="zoom: 67%;"></p>
<p>配置（Placement）是该框架的输入，Environment是Tensorflow按照这种配置在实际系统中的运行，Runtime作为运行时间进行输出。该输出经过处理（和Baseline）得到Loss，根据Loss进一步优化Placement配置。</p>
<p>其中的Placement是由序列到序列模型（Seq2Seq）也就是LSTM模型预测得到，该模型框架如下：</p>
<figure>
<img src="/archives/40cbe9ff/image-20200910190545553.png" alt="image-20200910190545553"><figcaption aria-hidden="true">image-20200910190545553</figcaption>
</figure>
<h3 id="步骤一placement由来">步骤一：Placement由来</h3>
<ul>
<li><p>模型输入</p>
<p>先收集计算图中的所有操作（operations），该模型输入是有关操作（operations）的属性，图中可以看到计算图一共是有100个operations，也就会有100个operations的属性输入进来。</p>
<p>每个操作（operations）有三个部分组成：</p>
<ol type="1">
<li><p>type：类型，例如矩阵乘法（MatMul）或者Conv2d（卷积操作），对操作的类型进行embedding操作，它是可以通过参数调整改变embedding之后向量长度的，所以是可变长（tunable）向量</p>
<blockquote>
<p>论文中并没有说明是如何进行embedding 的</p>
</blockquote></li>
<li><p>outputshape：定长向量，该操作输出的形状，拼接shape的时候按照output中shape维度最高的分配空间，就是论文中称为：<code>fixed-size zero-padded</code>.</p>
<blockquote>
<p>例如：有两个输出，其中一个形状是四维的[20. 40, 20, 30]，另一个形状是二维的[20, 30]，拼接在一起之后就是[20, 40, 20, 30, 0, 20, 30, 0]。</p>
</blockquote></li>
<li><p>adj：one-hot编码的属性，定长向量统计计算图中一共有多少个操作，并分别编号。然后对某op的输入输出进行one-hot编码</p></li>
</ol></li>
<li><p>模型输出</p>
<p>每个操作所对应的设备，计算图中有多少个操作（operations），这里就有多少个输出，图中有100个，这里的输出就是100个。</p></li>
</ul>
<h3 id="步骤二运行得到runtime并计算loss">步骤二：运行得到Runtime并计算Loss</h3>
<p><span class="math display">\[
J(\theta)=\mathbf{E}_{\mathcal{P} \sim \pi(\mathcal{P} \mid \mathcal{G} ; \theta)}[R(\mathcal{P}) \mid \mathcal{G}]
\]</span></p>
<p>最小化上述式子，其中<span class="math inline">\(\pi(\mathcal{P} \mid \mathcal{G} ; \theta)\)</span>表示策略就是第一步中的Placement，策略梯度下降方法计算如下： <span class="math display">\[
\nabla_{\theta} J(\theta)=\mathbf{E}_{\mathcal{P} \sim \pi(\mathcal{P} \mid \mathcal{G} ; \theta)}\left[R(\mathcal{P}) \cdot \nabla_{\theta} \log p(\mathcal{P} \mid \mathcal{G} ; \theta)\right]
\]</span> 实际上，论文中采用了均值的方法代替公式中的期望： <span class="math display">\[
\nabla_{\theta} J(\theta) \approx \frac{1}{K} \sum_{i=1}^{K}\left(R\left(\mathcal{P}_{i}\right)-B\right) \cdot \nabla_{\theta} \log p\left(\mathcal{P}_{i} \mid \mathcal{G} ; \theta\right)
\]</span></p>
<blockquote>
<p>含义：根据误差改变参数<span class="math inline">\(\theta\)</span>, 再根据新的<span class="math inline">\(\theta\)</span>修改LSTM模型得到新的配置（Placement），其中B表示历史平均的运行时间，作为基准（BaseLine）。</p>
</blockquote>
<ul>
<li><p>特殊情况：</p>
<ol type="1">
<li>某个配置（Placement）使得太多的操作放在同一个设备上导致内存不足，将该配置的runtime设置为很大的常数，可以带来巨大的Loss。</li>
<li>上述解决方案又会导致<span class="math inline">\(R(\mathcal{P}_i)\)</span>和<span class="math inline">\(B\)</span>的差距很大，特别在训练最后阶段导致局部最小范围内的剧烈抖动，解决方式是在5000步之后，采用硬编码方式，只有策略执行成功后，才作更新。</li>
</ol></li>
</ul>
<h3 id="分布式训练">分布式训练</h3>
<p>上述过程需要将其异步分布式运行，运行结构如下图所示：</p>
<p><img src="/archives/40cbe9ff/image-20200910194424134.png" alt="image-20200910194424134" style="zoom:80%;"></p>
<p>有多个Controller，每个Conctroller执行LSTM模型，生成Placement，并且他们与参数服务器通信。所有的参数服务器存储全局的LSTM模型参数。执行过程如下：</p>
<ol type="1">
<li>每个Controller按照公式（3）生成<span class="math inline">\(K\)</span>个Placement策略，同时<span class="math inline">\(K\)</span>也对应这<span class="math inline">\(K\)</span>个工作节点，Controller将K个Placement发给工作节点运行，每个工作节点运行一个Placement</li>
<li>运行完成后工作节点回传运行时间Runtime给Controller，也就是公式（3）中的<span class="math inline">\(R(\mathcal{P}_i)\)</span>。</li>
<li>Controller的参数<span class="math inline">\(\theta\)</span>会在参数服务器中做聚合操作，得到新模型后，Controller又会根据新的到的参数做MCMC采样，得到K个Placement策略继续迭代运行。</li>
</ol>
<h2 id="实验结果">实验结果</h2>
<h3 id="单步运行时间">单步运行时间</h3>
<p>下表提供了该方法和其他基准方法单步运行时间的对比：</p>
<figure>
<img src="/archives/40cbe9ff/image-20200911100320455.png" alt="image-20200911100320455"><figcaption aria-hidden="true">image-20200911100320455</figcaption>
</figure>
<p>对于每个模型来说，第一行表示1个CPU和2个GPU的结果；第二行表示1个CPU和4个GPU的结果。最后一列表示基于RL的配置方法和其他基准测试方法时间性能上的提升。</p>
<p>同时，作者还扩展了实验，将RNNLM和NMT的批量大小提高到了256，这两个模型中的LSTM提高到了4096和2048.这使得即使模型的单层都无法在单台设备中存储。从而排除了人为设计并行方案的可能。但是通过RL方法却能够找到可执行的分布式配置方案。</p>
<p>配置方案如下图所示:</p>
<figure>
<img src="/archives/40cbe9ff/image-20200911101244256.png" alt="image-20200911101244256"><figcaption aria-hidden="true">image-20200911101244256</figcaption>
</figure>
<h3 id="整体测试">整体测试</h3>
<p>下图中，人为最佳配置达到了229.57个小时的训练时间，采用RL方法达到了165.73的训练时间，速度上提升了27.8%。</p>
<p><img src="/archives/40cbe9ff/image-20200911102538193.png" alt="image-20200911102538193" style="zoom:67%;"></p>
<p>下图展示了三种不同模式下的Inception-V3训练曲线，从图中可以看到，与同步的模式相比，基于RL的配置方式可以将训练时间加速19.7%。然而，异步的方法每步的执行时间更少，同步方法的收敛速率更快。基于RL的方法在刚开始时候的收敛速率比较慢，但是最终可以赶超异步的方法。</p>
<h2 id="总结">总结</h2>
<p>优点：</p>
<ol type="1">
<li><p>具有可一致性和普遍性，如果人为的根据异构的设备结构和网络结构设计并行策略，只能用于特定的环境，可移植性较差。</p></li>
<li><p>提供了用机器学习的方法来制定并行策略的方式，提供了这种新思路。</p></li>
<li><p>速度上有20%的提升</p></li>
</ol>
<p>缺点：</p>
<ol type="1">
<li>结果的提升只有20%多一点，效果可能不是非常明显</li>
<li>寻找并行策略的过程本身需要投入大量的资源进行运算，例如本论文中需要20个Controller节点，每个Controller节点又要分配4-8个Worker进行计算，其投入量相当巨大，只为了计算出较为合适的并行策略，有一些不值当。</li>
</ol>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/60fdd68b.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/60fdd68b.html" class="post-title-link" itemprop="url">Communication Optimal Parallel Multiplication of Sparse Random Matrices</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-09-10 09:17:43" itemprop="dateCreated datePublished" datetime="2020-09-10T09:17:43+08:00">2020-09-10</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-07 10:33:31" itemprop="dateModified" datetime="2020-10-07T10:33:31+08:00">2020-10-07</time>
              </span>

          
            <span id="/archives/60fdd68b.html" class="post-meta-item leancloud_visitors" data-flag-title="Communication Optimal Parallel Multiplication of Sparse Random Matrices" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/60fdd68b.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/60fdd68b.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>0</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/62b3642.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/62b3642.html" class="post-title-link" itemprop="url">Beyond Data and Model Parallelism for Deep Neural Networks</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-09-09 20:29:02" itemprop="dateCreated datePublished" datetime="2020-09-09T20:29:02+08:00">2020-09-09</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-09-24 19:46:21" itemprop="dateModified" datetime="2020-09-24T19:46:21+08:00">2020-09-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">分布式机器学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文阅读笔记</span></a>
                </span>
            </span>

          
            <span id="/archives/62b3642.html" class="post-meta-item leancloud_visitors" data-flag-title="Beyond Data and Model Parallelism for Deep Neural Networks" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/62b3642.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/62b3642.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>6 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="beyond-data-and-model-parallelism-for-deep-neural-networks">Beyond Data and Model Parallelism for Deep Neural Networks</h1>
<ul>
<li><p>题目：深度神经网络的数据和模型并行性</p>
<p>英文：<a href="https://arxiv.org/pdf/1807.05358" target="_blank" rel="noopener external nofollow noreferrer">Beyond Data and Model Parallelism for Deep Neural Networks</a></p></li>
<li><p>作者：贾志豪 斯坦福大学</p></li>
</ul>
<h2 id="摘要">摘要</h2>
<p>现有的深度网络的并行主要是通过数据和模型并行实现，这些方法往往是次优的，而且考虑并行的维度比较少。本文定义了一种更宽泛的DNN并行搜索策略，称为SOAP，它将从样本（Sample），操作（Opration）、属性（Attribute）以及参数（Parameter）这四个维度对最优的并行策略进行探索和优化。同时本文还提出了FlexFlow，在SOAP范围内随机搜索并行策略的方法。为了加速搜索，FlexFlow提出了一种新的执行模拟器（Execution Optimizer），模拟执行比真实环境运行的吞吐量提高了3.8倍。</p>
<h2 id="主要贡献">主要贡献</h2>
<ol type="1">
<li>为并行DNN应用定义了SOAP搜索空间，它包括了样本（Sample），操作（Opration）、属性（Attribute）以及参数（Parameter）这四个维度下的并行策略。</li>
<li>在合理假设下，DNN的并行仿真所用时间比DNN直接在真实硬件系统下运行时间少三个数量级</li>
<li>描述了FlexFlow框架，能够从SOAP空间寻找并行执行策略，从而加速DNN训练</li>
<li>FlewFlow与现有框架相比，能够提升3.8倍的训练吞吐量，并且提升了可扩展性。</li>
</ol>
<h2 id="简介和背景">简介和背景</h2>
<p>神经网络并行最常用的方法是数据和模型并行，但是数据并行和模型并行都有如下特点和弊端：</p>
<ol type="1">
<li>数据并行（Data Parallelism）</li>
</ol>
<p>适用于参数较少，且计算集中的DNN，但是对于具有大量参数的操作性能不佳（例如：矩阵乘法）。</p>
<p>数据并行<a href="#refer-anchor-1"><sup>[1]</sup></a>广泛应用于现有的深度学习系统（例如：Tensorflow、Caffe2以及Pytorch），但数据并行需要在每个工作节点上都复制一份完整网络，在参数量较大的情况下将成为性能瓶颈。</p>
<ol start="2" type="1">
<li>模型并行（model parallelism）</li>
</ol>
<p>模型并行[15]消除了参数在设备之间同步的开销，但是需要在操作时的数据转换，并且不允许内部操作的并行化。</p>
<ol start="3" type="1">
<li>专家设计策略（expert-desgned strategies）</li>
</ol>
<p>根据专家的经验和知识手动优化并行策略，例如<a href="#refer-anchor-3"><sup>[3]</sup></a> <a href="#refer-anchor-4"><sup>[4]</sup></a>对<code>卷积层</code>和<code>池化层</code>采用<code>数据并行</code>，对<code>全连接层</code>转换为<code>模型并行</code>加速训练卷积神经网络。这样的方法相比于数据和模型并行提高了性能，但是依然是次优的。</p>
<ol start="4" type="1">
<li>自动并行化策略（automated frameworks）</li>
</ol>
<p>在特定的搜索域内自动化寻找最优的并行策略.</p>
<ul>
<li>REINFORCE <a href="#refer-anchor-6"><sup>[6]</sup></a></li>
</ul>
<p>采用强化学习模型在实际设备上运行不同策略来为模型并行学习得到高效操作策略。但是该方法通过对每种并行策略执行真实迭代来衡量执行时间的方式依然非常低效，而且所需硬件要求非常高。</p>
<ul>
<li>OptCNN <a href="#refer-anchor-5"><sup>[5]</sup></a></li>
</ul>
<p>OptCNN也是本文作者所提出，是一种基于线性计算图的CNN逐层并行化方法。它使用动态编程的方法联合优化每种算法，考虑了运算内部的并行，但没有考虑运算操作之间的并行。</p>
<p>现有的自动化框架只是探究了不同操作的并行化（例如REINFORCE[33]）或者在单个操作中的并行（例如OptCNN），忽略了在两个维度上都使用并行性的更快策略。</p>
<blockquote>
<p>除了数据并行和模型并行之外的并行维度可以进一步替身DNN的训练效率。因此作者首先提出了SOAP的概念。</p>
</blockquote>
<h2 id="soap并行搜索空间">SOAP并行搜索空间</h2>
<p>SOAP表示样本（Sample），操作（Opration）、属性（Attribute）以及参数（Parameter）这四个维度：在SOAP空间中搜索可能的并行策略。</p>
<ul>
<li>Sample 划分训练样本（数据并行）</li>
</ul>
<p><img src="/archives/62b3642/image-20200915145646678.png" alt="image-20200915145646678" style="zoom: 50%;"></p>
<ul>
<li>Operators 划分DNN操作（模型并行）</li>
</ul>
<p><img src="/archives/62b3642/image-20200915150006162.png" alt="image-20200915150006162" style="zoom:50%;"></p>
<ul>
<li><p>Attributs 划分样本的特征（数据并行）</p>
<p><img src="/archives/62b3642/image-20200915150454252.png" alt="image-20200915150454252" style="zoom:50%;"></p></li>
<li><p>Parameter 划分操作中的参数</p>
<p><img src="/archives/62b3642/image-20200915150831384.png" alt="image-20200915150831384" style="zoom: 33%;"></p></li>
</ul>
<p>混合并行的模型如下图所示：</p>
<p><img src="/archives/62b3642/image-20200915150952707.png" alt="image-20200915150952707" style="zoom:67%;"></p>
<p>下表展示了现有并行技术所涉及的到的一些的并行维度：</p>
<p><img src="/archives/62b3642/image-20200915151116742.png" alt="image-20200915151116742" style="zoom: 80%;"></p>
<figure>
<img src="/archives/62b3642/image-20200915151437838.png" alt="image-20200915151437838"><figcaption aria-hidden="true">image-20200915151437838</figcaption>
</figure>
<blockquote>
<p>接下来的任务就是如何从SOAP这几个维度对复杂DNN的并行策略进行搜索，找到最佳的并行策略。</p>
</blockquote>
<h2 id="架构概述">架构概述</h2>
<p>实现了FlexFlow框架，如下图所示，将两个图作为输入，操作图（Operator Graph），描述了操作之间的通信情况；设备结构图（Device Topology），描述了设备之间的内在联系和结构。这两个图将作为输入传入执行优化器（Execution Optimizer）中，在该执行器中，将采用MCMC马尔科夫蒙特卡罗采样生成候选的并行策略，并将该并行策略传入执行模拟器（Execution Smulator）（本质上是一个Cost Model）模拟产生在该并行策略下的执行性能（时间），并传回到MCMC采样，用于后续生成候选策略。</p>
<p>这个迭代过程完成后，最佳的并行策略将发送至分布式执行引擎中，完成分布式训练。</p>
<p><img src="/archives/62b3642/image-20200910084035262.png" alt="image-20200910084035262" style="zoom: 80%;"></p>
<p>FlexFlow采用操作图<span class="math inline">\(\mathcal{G}\)</span>描述所有的DNN操作和状态。每个节点<span class="math inline">\(o_{i} \in \mathcal{G}\)</span>都表示一个操作（例如：矩阵乘法和卷积等），每个边<span class="math inline">\((o_i, o_j) \in \mathcal{G}\)</span>表示 输出<span class="math inline">\(o_i\)</span>和输入<span class="math inline">\(o_j\)</span>的张量。FlexFlow将设备拓扑结构记为<span class="math inline">\(\mathcal{D} = \left(\mathcal{D}_{N}, \mathcal{D}_{E}\right)\)</span>，描述了所有可能的硬件设备和它们的内在联系，每个节点<span class="math inline">\(d_{i} \in \mathcal{D}_{N}\)</span>代表设备（例如CPU或者是GPU），每条边<span class="math inline">\(\left(d_{i}, d_{j}\right) \in \mathcal{D}_{E}\)</span>代表硬件之间的连接（例如NVLink, PCI-e或者是网络连接）。每条边都标注有带宽或者延迟。FlexFlow会为操作图和设备拓扑找到一个并行策略，对比现有的框架，FlexFlow具有如下优点：</p>
<ol type="1">
<li>可编程性：对于在拓扑结构非常深的集群上运行的复杂操作图，设计高效的操作是非常困难的，FlexFlow可以找到高效的并行策略，并提供更加丰富的可编程接口。</li>
<li>可移植性，一种并行策略在一个集群中适用，但在别的集群中是不适用的，而然，FlewFlow可以自动根据集群中硬件的配置，根据应用特点自动寻找适合的并行策略。</li>
</ol>
<h3 id="采样方法马尔科夫链蒙特卡罗采样">采样方法（马尔科夫链蒙特卡罗采样）</h3>
<p>对于MCMC采样本本身不再赘述，主要针对该应用场景下，论文的描述：</p>
<p>MCMC采样技术是为了在已有的概率分布下获得样本。一种通用的方法是将该策略所要花费的时间转换为概率分布： <span class="math display">\[
p(\mathcal{S}) \propto \exp (-\beta \cdot \operatorname{cost}(\mathcal{S}))
\]</span> MCMC开始时（随机或其他初始化方法）生成初始策略，然后生成一系列能够保证所采样得到的样本点在极限状况下接近<span class="math inline">\(p(.)\)</span>所给定的分布。在本文中，从<span class="math inline">\(\mathcal{S}_0\)</span>这个策略开始生成一系列策略<span class="math inline">\(\mathcal{S}_{0}, \mathcal{S}_{1}, \ldots\)</span>。</p>
<p>这里采用MH算法（MCMC采样方法的一个变种）来生成马尔科夫链，它包含了当前策略<span class="math inline">\(\mathcal{S}_0\)</span>和新提出的另一种策略<span class="math inline">\(\mathcal{S}\)</span>。并且使得分布式满足<span class="math inline">\(q\left(\mathcal{S} \mid \mathcal{S}^{*}\right)=q\left(\mathcal{S}^{*} \mid \mathcal{S}\right)\)</span>。从而可以将接受率变为： <span class="math display">\[
\begin{array}{l}
\alpha\left(\mathcal{S} \rightarrow \mathcal{S}^{*}\right)=\min \left(1, p\left(\mathcal{S}^{*}\right) / p(\mathcal{S})\right) \\
=\min \left(1, \exp \left(\beta \cdot\left(\operatorname{cost}(\mathcal{S})-\operatorname{cost}\left(\mathcal{S}^{*}\right)\right)\right)\right.
\end{array}
\]</span> 如果<span class="math inline">\(\mathcal{S}^{*}\)</span>的成本比<span class="math inline">\(\mathcal{S}\)</span>低，那么<span class="math inline">\(\mathcal{S}^{*}\)</span>总是被接收；如果<span class="math inline">\(\mathcal{S}^{*}\)</span>的成本比<span class="math inline">\(\mathcal{S}\)</span>高，那么<span class="math inline">\(\mathcal{S}^{*}\)</span>也有可能被接受，接受概率如上。</p>
<p>该搜索不会自动停止，我们设置满足下面两个条件之一可自动停止：（1）当前初始策略搜索时间预算耗尽（在本方法中不至于到达该条件）；（2）在当前搜索时间一半时间内，搜索过程不能进一步改进发现的最佳策略则停止。</p>
<h3 id="cost-model">Cost Model</h3>
<p>由于在真实的硬件设备上执行候选并行策略非常缓慢，而且需要耗费大量的物理硬件。所以采用仿真的方式，在研究过程中，DNN具有如下两个特性：</p>
<ol type="1">
<li>DNN操作的计算性能具有高度的可预测性</li>
<li>几乎大量的操作都是类似的重复操作，只有少部分是特有的操作</li>
</ol>
<p>所以执行模拟（Execution Simulator）将会衡量每个特有的操作，并将得到结果去模拟不同的并行策略</p>
<h4 id="例子">例子</h4>
<p>下图是比较简单的循环神经网络的执行拓扑，包括了Embedding层，Recurrent层和Linear层，图a下方展示了某种并行策略的例子，对于前四个操作，分别采用两个任务的数据并行（Sample维度）策略。</p>
<figure>
<img src="/archives/62b3642/image-20200915161836032.png" alt="image-20200915161836032"><figcaption aria-hidden="true">image-20200915161836032</figcaption>
</figure>
<p>右侧是任务图，其中四边形代表计算任务，六边形的代表通信任务，任务的运行时间使用操作模拟的值，数据通信转换的时间采用张量的尺寸/通道带宽进行表示（这里的假设是，通信带宽能够被完全使用，达到最佳）。</p>
<h3 id="delta模拟算法delta-simulation">Delta模拟算法（Delta Simulation）</h3>
<p>在有新的并行候选策略生成时，并不完全重构任务图模型，而只是做拒不修改，所以大部分的图模型是不发生改变的，所以可以采用增量更新的方式重用之前的仿真模拟，这样的方法被称为Delta仿真算法。还是以上述例子为例，</p>
<figure>
<img src="/archives/62b3642/image-20200915163749550.png" alt="image-20200915163749550"><figcaption aria-hidden="true">image-20200915163749550</figcaption>
</figure>
<p>假设此时并行策略此时发生了改变，第五个操作从原来的分派两个任务进行执行，变为单任务执行，那此时只需要对灰色部分进行重新模拟仿真即可，而不需要重构真个计算图模型。</p>
<h4 id="delta模拟的性能表现">Delta模拟的性能表现</h4>
<p>作者做了实验，对比了是否使用Delta模拟算法的计算性能</p>
<p><img src="/archives/62b3642/image-20200915164059189.png" alt="image-20200915164059189" style="zoom: 50%;"></p>
<p>横坐标表示时间，纵坐标表示找到的最好的并行策略，可以发现，采用Delta Simulation的时间可以缩短2.3倍，具有极大的提升。</p>
<p>从图中我们还可以发现FlexFlow找到最佳并行策略的时间只需要几分钟，在单个节点上就能完成。这就和REINFORCE方法形成了强烈的反差，REINFORCE方法在策略的寻找上就需要分布式的环境，并需要耗费几个小时的时间。</p>
<h2 id="实验性能">实验性能</h2>
<p>该实验主要针对以下两种GPU架构体系，图中箭头表示NVLink连接。实线表示PCI-e连接，虚线表示跨不同节点的无线带宽连接。</p>
<p><img src="/archives/62b3642/image-20200921104739363.png" alt="image-20200921104739363" style="zoom:67%;"></p>
<p>左边第一个集群包含了四个计算节点，每个计算节点配备了两个Intel 10-core E5-2600 CPU, 256GB内存，以及四个NVIDIA Tesla P100 GPU，GPU之间都通过VNLink进行连接。节点通过100GB/s EDR的无线带宽技术。</p>
<p>右边的集群包含了16个节点，每个节点配备两个Intel 10-core E5-2600 CPU, 256GB内存，以及四个NVIDIA Tesla K80 GPU。GPU之间通过PCI-e连接，集群中的计算节点连接超过56GB/s EDR的无线带宽技术。</p>
<p>从实验的角度来说，GPU之间都是同构的设备，但我感觉是从算法的角度考虑，如果在异构的环境下，他可以通过计算时间这个reward去衡量那种策略更优，感觉它已经将异构的情况考虑在内了，选择最优策略的参数会偏向于将更复杂的内容交给性能更好的GPU，这样最后的时间会更快。</p>
<ul>
<li>与数据并行，人为设计的并行策略在单次迭代执行时间的对比</li>
</ul>
<figure>
<img src="/archives/62b3642/image-20200915164847178.png" alt="image-20200915164847178"><figcaption aria-hidden="true">image-20200915164847178</figcaption>
</figure>
<ul>
<li><p>训练吞吐量上和REINFORCE和OptCNN等自动并行策略的现有方法做对比</p>
<figure>
<img src="/archives/62b3642/image-20200915164707545.png" alt="image-20200915164707545"><figcaption aria-hidden="true">image-20200915164707545</figcaption>
</figure></li>
</ul>
<p>可以发现在吞吐量上有明显的提升。</p>
<ul>
<li>Simulated Execution仿真模拟的准确率</li>
</ul>
<figure>
<img src="/archives/62b3642/image-20200915164938253.png" alt="image-20200915164938253"><figcaption aria-hidden="true">image-20200915164938253</figcaption>
</figure>
<p>可以看到在各种设备拓扑结构下，结果基本是准确的。</p>
<h2 id="总结">总结</h2>
<p>本文定义了一种更宽泛的DNN并行搜索策略，称为SOAP，它将从样本（Sample），操作（Opration）、属性（Attribute）以及参数（Parameter）这四个维度对最优的并行策略进行探索和优化。并提出了FlexFlow自动搜索并行方案的框架，能在时间性能上比Google的REINFORCE方法提高了3.8倍。</p>
<div id="refer-anchor-1">

</div>
<ul>
<li>[1] <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener external nofollow noreferrer">Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Advances in neural information processing systems. 2012: 1097-1105.</a>
<div id="refer-anchor-2">

</div></li>
<li>[2] <a href="http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf" target="_blank" rel="noopener external nofollow noreferrer">Dean J, Corrado G, Monga R, et al. Large scale distributed deep networks[C]//Advances in neural information processing systems. 2012: 1223-1231.</a>
<div id="refer-anchor-3">

</div></li>
<li>[3] <a href="https://arxiv.org/pdf/1404.5997" target="_blank" rel="noopener external nofollow noreferrer">Krizhevsky A. One weird trick for parallelizing convolutional neural networks[J]. arXiv preprint arXiv:1404.5997, 2014.</a>
<div id="refer-anchor-4">

</div></li>
<li>[4] <a href="https://arxiv.org/pdf/1609.08144.pdf%20(7)" target="_blank" rel="noopener external nofollow noreferrer">Wu Y, Schuster M, Chen Z, et al. Google's neural machine translation system: Bridging the gap between human and machine translation[J]. arXiv preprint arXiv:1609.08144, 2016.</a>
<div id="refer-anchor-5">

</div></li>
<li>[5] <a href="https://arxiv.org/abs/1802.04924" target="_blank" rel="noopener external nofollow noreferrer">Jia Z, Lin S, Qi C R, et al. Exploring hidden dimensions in parallelizing convolutional neural networks[J]. arXiv preprint arXiv:1802.04924, 2018.</a>
<div id="refer-anchor-6">

</div></li>
<li>[6] <a href="https://patentimages.storage.googleapis.com/2b/03/41/324a4ae429b203/US10692003.pdf" target="_blank" rel="noopener external nofollow noreferrer">Mirhoseini A, Pham H, Le Q V, et al. Device placement optimization with reinforcement learning[J]. arXiv preprint arXiv:1706.04972, 2017.</a></li>
</ul>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/6fa57430.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/6fa57430.html" class="post-title-link" itemprop="url">2020.08.26小组汇报</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-26 16:10:11" itemprop="dateCreated datePublished" datetime="2020-08-26T16:10:11+08:00">2020-08-26</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-28 19:34:09" itemprop="dateModified" datetime="2020-08-28T19:34:09+08:00">2020-08-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%B0%8F%E7%BB%84%E6%B1%87%E6%8A%A5/" itemprop="url" rel="index"><span itemprop="name">小组汇报</span></a>
                </span>
            </span>

          
            <span id="/archives/6fa57430.html" class="post-meta-item leancloud_visitors" data-flag-title="2020.08.26小组汇报" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/6fa57430.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/6fa57430.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>3.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          此文加密，请输入密码
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/archives/6fa57430.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/5cf57987.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/5cf57987.html" class="post-title-link" itemprop="url">分布式学习通信优化综述（2020香港大学）</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-26 14:13:54" itemprop="dateCreated datePublished" datetime="2020-08-26T14:13:54+08:00">2020-08-26</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-11 13:46:09" itemprop="dateModified" datetime="2020-10-11T13:46:09+08:00">2020-10-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">分布式机器学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%9A%E4%BF%A1%E4%BC%98%E5%8C%96/" itemprop="url" rel="index"><span itemprop="name">通信优化</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%9A%E4%BF%A1%E4%BC%98%E5%8C%96/%E6%A2%AF%E5%BA%A6%E5%8E%8B%E7%BC%A9/" itemprop="url" rel="index"><span itemprop="name">梯度压缩</span></a>
                </span>
            </span>

          
            <span id="/archives/5cf57987.html" class="post-meta-item leancloud_visitors" data-flag-title="分布式学习通信优化综述（2020香港大学）" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/5cf57987.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/5cf57987.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>10k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>9 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>综述名</strong>：Communication-Efficient Distributed Deep Learning: A Comprehensive Survey</p>
<p><strong>发表年限：</strong>2020</p>
<p><strong>简介：</strong>从以下四个维度对分布式训练算法进行介绍</p>
<ol type="1">
<li><p>通信同步和频次</p>
<p>主要有以下两个方向：</p>
<p>（1）宽松同步条件为异步并行（ASGD）或延迟同步并行（SSP）</p>
<p>（2）本地多次迭代后进行通信</p></li>
<li><p>系统架构和梯度聚合</p>
<p>（1）宽松参数服务器架构中的拥塞问题，MPI的去中心化拓扑</p>
<p>（2）Gossip架构</p>
<blockquote>
<p>工作节点能够从听一个或多个节点中获取模型，解决拥塞问题，并且减少了通信量</p>
</blockquote></li>
<li><p>压缩技术</p>
<p>（1）量化</p>
<p>（2）编码</p>
<p>（3）稀疏化</p></li>
<li><p>通信和计算的并行</p>
<p>简称为流水线算法，使得通信和计算充分并行。</p></li>
</ol>
<p>分布式SGD通信优化——以表格方式归纳如下：</p>
<table>
<thead>
<tr class="header">
<th>维度</th>
<th>方法</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>通信同步和频次</td>
<td>同步方法（SGD）<br>延迟受限同步<br>异步方法（ASGD）<br>本地SGD</td>
</tr>
<tr class="even">
<td>系统架构</td>
<td>参数服务器架构<br>All-Reduce架构<br>Gossip架构</td>
</tr>
<tr class="odd">
<td>压缩技术</td>
<td>量化<br>编码<br>稀疏化</td>
</tr>
<tr class="even">
<td>计算和同行并行</td>
<td>流水线方法<br>调度方法</td>
</tr>
</tbody>
</table>
<h2 id="分布式学习分类">分布式学习分类</h2>
<h3 id="通信同步和频次">通信同步和频次</h3>
<h4 id="同步并行">同步并行</h4>
<h4 id="受限同步并行">受限同步并行</h4>
<p>[Chen et al.] <a href="#refer-anchor-1"><sup>[1]</sup></a>提出了候补节点<span class="math inline">\(n_e\)</span>。主要思想是当有<span class="math inline">\(n\)</span>个节点到达之后，就不再等待梯度还未到达的<span class="math inline">\(n_e\)</span>个节点。它们的梯度值将会被舍去。</p>
<p>[Ho et al.] <a href="#refer-anchor-2"><sup>[2]</sup></a>提出了SSP模型，设定了一个阈值，允许在阈值之内，计算较快的工作节点迭代更多次数并更新全局参数，但是当最快节点和最慢节点到达阈值时，快速的节点需要等待慢速的节点回归合理阈值。</p>
<p>对于<code>拥塞问题</code>，[Chen et al] 提出了Round-Robin同步并行方法，该算法在整个训练过程中均匀交错工作节点更新，并以固定的循环顺序协调工作节点更新梯度。</p>
<h4 id="异步并行">异步并行</h4>
<p>[Mote et al.] <a href="#refer-anchor-3"><sup>[3]</sup></a>提出了高通信效率的分布式交替方向乘数法（D-ADMM），他是对ADMM算法的扩展。[Wei et al.] <a href="#refer-anchor-6"><sup>[6]</sup></a><a href="#refer-anchor-7"><sup>[7]</sup></a>将其拓展为去中心化的ADMM算法。</p>
<p>之后有更多的学者对ADMM算法进行优化 <a href="#refer-anchor-7"><sup>[7]</sup></a>，[Li et al.] <a href="#refer-anchor-8"><sup>[8]</sup></a>提出了延迟闭塞近端梯度法（Delayed Block Proximal Gradient Method），该算法只在每次迭代过程中异步更新参数中的一块内容，因此在通信的过程中只需要上传一部分参数。</p>
<p>[Grishchenko et al.]提出了一种异步分配算法，其特点是向上通信(从工人到主人)的稀疏化，他们通过对本地更新条目的统一抽样选择来实现稀疏化，这使得通信更加高效。</p>
<p>但是异步的方法往往收敛性得不到保证。</p>
<h4 id="本地sgd">本地SGD</h4>
<p>基本思想是在多轮迭代之后进行通信<a href="#refer-anchor-9"><sup>[9]</sup></a><a href="#refer-anchor-10"><sup>[10]</sup></a><a href="#refer-anchor-11"><sup>[11]</sup></a><a href="#refer-anchor-12"><sup>[12]</sup></a><a href="#refer-anchor-13"><sup>[13]</sup></a><a href="#refer-anchor-14"><sup>[14]</sup></a><a href="#refer-anchor-15"><sup>[15]</sup></a><a href="#refer-anchor-16"><sup>[16]</sup></a><a href="#refer-anchor-17"><sup>[17]</sup></a>。</p>
<p>[Yu et al.] <a href="#refer-anchor-18"><sup>[18]</sup></a>结合了分布式动量的SGD方法和PR-SGD<a href="#refer-anchor-19"><sup>[19]</sup></a>方法来提高了本地SGD方法的性能，并且证明了线性加速比。</p>
<p>[Jiang et al.] <a href="#refer-anchor-20"><sup>[20]</sup></a>将量化方法和本地SGD方法做了结合，降低了通信的复杂度。</p>
<p>其他能够减少通信数据量的方法是提高批量大小。[Yu et al.] <a href="#refer-anchor-21"><sup>[21]</sup></a>提出了Catalyst-like<a href="#refer-anchor-22"><sup>[22]</sup></a><a href="#refer-anchor-23"><sup>[23]</sup></a>算法，能够在每轮迭代之后动态提高批量大小，并达到和SSP方法下沟通的收敛速率。</p>
<p>大批量的SGD方法会使得泛化性能降低。[Lin et al.] <a href="#refer-anchor-24"><sup>[24]</sup></a>提出了post-local SGD方法来解决这个问题。该算法将整个训练过程分为两个阶段，第一阶段采用小批量SGD，第二阶段采用局部SGD。</p>
<h3 id="中心化和去中心化架构">中心化和去中心化架构</h3>
<h3 id="量化方法">量化方法</h3>
<h4 id="方法一">方法一</h4>
<p>数据并行下的梯度量化方法其实是一种分布式平均估计问题<a href="#refer-anchor-25"><sup>[25]</sup></a><a href="#refer-anchor-26"><sup>[26]</sup></a>。[Suresh et al] <a href="#refer-anchor-25"><sup>[25]</sup></a>和[Jakub et al] <a href="#refer-anchor-26"><sup>[26]</sup></a>对分布式平均估计进行了通信效率算法的分析。他们使用均方误差的方法，并提出了一种在给定通信成本下的编码策略以达到最佳的MSE。为了减少通信成本，[Suresh et al.] <a href="#refer-anchor-25"><sup>[25]</sup></a> 提出了两种方法，随机旋转量化（Stochastic Rotated Quantization），所有工作节点和中央服务器生成一个全局随机旋转矩阵，并尝试找到一个正交矩阵<span class="math inline">\(\mathbb{R}\)</span>。变长编码（Variable Length Coding）采用对应每个量化值出现次数的霍夫曼编码算法。</p>
<h4 id="方法二">方法二</h4>
<p>[Sei et al.] <a href="#refer-anchor-27"><sup>[27]</sup></a> 为了降低量化误差带来的负面影响，作者使用了误差补偿技术：每次量化时，把上一次迭代的量化误差加到本次迭代的梯度上，然后再进行量化，接着求出本次量化操作的误差。这种误差补偿机制可以确保所有的梯度都会再一定程度上对模型更新产生作用，只不过这种作用分散在不同的迭代中——类似于一种延迟更新的形式。作者指出，使用误差补偿后，就可以在几乎不损失模型精度的情况下将梯度由32位量化成1位。 <span class="math display">\[
\begin{aligned}
G_{i j \ell}^{\text {quant }}(t) &amp;=\mathcal{Q}\left(G_{i j \ell}(t)+\Delta_{i j \ell}(t-N)\right) \\
\Delta_{i j \ell}(t) &amp;=G_{i j \ell}(t)-\mathcal{Q}^{-1}\left(G_{i j \ell}^{\text {quant }}(t)\right)
\end{aligned}
\]</span> 其中<span class="math inline">\(\mathcal{Q}(\cdot)\)</span>表示量化函数，<span class="math inline">\(G_{i j \ell}^{\text {quant }}(t)\)</span>表示量化之后的整型数值。我们在量化过程中会保证<span class="math inline">\(\Delta_{i j \ell}(t)\)</span>被加到下一轮的梯度过程中（也称为了误差补偿机制）。</p>
<p>举个例子，在具体的实现上，比较简单的方法是将大于<span class="math inline">\(0\)</span>的梯度值编码成为<span class="math inline">\(1\)</span>，小于等于<span class="math inline">\(0\)</span>的梯度值编码为<span class="math inline">\(0\)</span>。在解码的时候，将<span class="math inline">\(1\)</span>编码为<span class="math inline">\(+1\)</span>，将<span class="math inline">\(0\)</span>解码为<span class="math inline">\(-1\)</span>，在进行聚合操作。</p>
<p>其他一些研究采用不精确的近端梯度提出了自适应的量化方法[168][169]，但是这些方法缺乏在深度学习模型种的实践。</p>
<p>考虑到需要同时具备高通信效率和好的收敛性，[Alistarh et al.] <a href="#refer-anchor-28"><sup>[28]</sup></a> 提出了一种基于量化的算法，而不仅仅只是量化方法。这种量化算法叫做QSGD，可以平衡传输的比特数与压缩梯度的方差。</p>
<h4 id="方法三">方法三</h4>
<p>[Wen et al.] <a href="#refer-anchor-29"><sup>[29]</sup></a> 提出了另一种叫做TernGrad的压缩通信量的模式，它可以使用三元梯度来加速分布式深度学习。在TernGrad中，梯度<span class="math inline">\(G(x)\)</span>被量化为三元组<span class="math inline">\(\{-1,0,1\}\)</span>来减少通信量化大小。梯度<span class="math inline">\(G(x)\)</span>量化如下： <span class="math display">\[
\tilde{Q}_{t}\left(G\left(\mathbf{x}_{t}\right)\right)=\operatorname{ternarize}\left(G\left(\mathbf{x}_{t}\right)\right)=s_{t} \cdot \operatorname{sign}\left(G\left(\mathbf{x}_{t}\right)\right) \circ \mathbf{b}_{t}
\]</span> 其中<span class="math inline">\(s_{t}:=\max \left(a b s\left(G\left(\mathbf{x}_{t}\right)\right)\right)\)</span>以及$ <span class="math inline">\(表示哈达玛积。\)</span>()<span class="math inline">\(和SGD中的\)</span>()<span class="math inline">\(是一致的。每个\)</span>b_t$元素遵循如下分布： <span class="math display">\[
\begin{array}{l}
P\left(b_{t, j}=1 \mid G_{t}\left(\mathbf{x}_{t}\right)\right)=\left|G_{t, j}\left(\mathbf{x}_{t}\right) / s_{t}\right| \\
P\left(b_{t, j}=0 \mid G_{t}\left(\mathbf{x}_{t}\right)\right)=1-\left|G_{t, j}\left(\mathbf{x}_{t}\right) / s_{t}\right|
\end{array}
\]</span></p>
<h4 id="方法四">方法四</h4>
<p>Sign-SGD是另外一种量化方法 <a href="#refer-anchor-30"><sup>[30]</sup></a>。在Sign-SGD中，每个工作节点将梯度量化为二进制值，它是梯度向量的每个坐标的符号。[Bernstein et al.] <a href="#refer-anchor-31"><sup>[31]</sup></a>提供了基于该方法在非凸优化上的理论分析。他们证明了当梯度与随机度和曲率一样稠密或更密集时，Sign-SGD可以以一个理论速率收敛。[Bernstein et al.] <a href="#refer-anchor-31"><sup>[31]</sup></a>还提出了一种具有大多数投票的Sign-SGD方法。在工作节点将他们的梯度向量的符号交换到服务器后，整体的更新由多数人投票决定。通过这种方法，将通信成本降低了32倍。</p>
<h4 id="方法五">方法五</h4>
<p>[Wang et al.] <a href="#refer-anchor-32"><sup>[32]</sup></a>提出了一种新的方法叫做原子稀疏化方法（Atomic Sparsification (ATOMO)）。他证明了梯度稀疏化和量化是原子分解过程中梯度稀疏化的一般方法的一部分，例如QSGD、奇异值分解（SVD）、傅里叶分解等。ATOMO的目标是最小化在原子基础上稀疏的稀疏梯度的方差，并保持它作为原始梯度的无偏估计量。它们说明了1位的QSGD和TernGrad是ATOMO的特殊情况。此外，他们用SVD改进了ATOMO，称为Spectral-ATOMO。在他们的实验中，与QSGD和TernGrad相比，Spectral-ATOMO分别减少了2倍和3倍的训练时间。</p>
<h4 id="方法六">方法六</h4>
<p>[Mishchenko et al.] <a href="#refer-anchor-33"><sup>[33]</sup></a>介绍了DIANA这种创新方法，它扩展了QSGD和Terngrad这两种方法，将这个梯度向量划分成多个子向量，并将每个子向量进行独立压缩。</p>
<h4 id="方法七">方法七</h4>
<p>[Sun et al.] <a href="#refer-anchor-34"><sup>[34]</sup></a>的LAQ方法</p>
<h4 id="方法八">方法八</h4>
<p>[Horvth et al.] <a href="#refer-anchor-36"><sup>[36]</sup></a>提出了一种新的压缩方法，叫做自然压缩(Natural Compression)。这种压缩方法定义如下： <span class="math display">\[
C_{n a t}(t):=\left\{\begin{array}{ll}
\operatorname{sign}(t) \cdot 2^{\left\lfloor\log _{2}|t|\right\rfloor}, &amp; \text { with probability } p(t) \\
\operatorname{sign}(t) \cdot 2^{\left\lfloor\log _{2}|t|\right\rfloor}, &amp; \text { with probability } 1-p(t)
\end{array}\right.
\]</span></p>
<p>其中<span class="math inline">\(p(t):=\frac{2^{\left\lceil\log _{2}|t|-|t|\right\rceil}}{2^{\left\lfloor\log _{2}|t|\right\rfloor}}\)</span>。他们提出的这种压缩方法能够将方差忽略不计，因此有较好的收敛性。这个方法的一个优势是<span class="math inline">\(C_{nat}\)</span>能够去掉二进制表示中的尾数。他们提出了与QSGD的抖动是类似的。</p>
<p>[Yu et al.] <a href="#refer-anchor-35"><sup>[35]</sup></a>提出了名为AsyLPGd低精度算法，在异步框架中使用，同时量化梯度和模型参数。它使用额外的要求来限制量化级别。他们将稀疏化方法和AsyLPG相结合，进一步降低通信的复杂度。</p>
<h3 id="稀疏化方法">稀疏化方法</h3>
<h3 id="计算和通信流水线调度">计算和通信流水线调度</h3>
<h2 id="未来优化方向">未来优化方向</h2>
<h2 id="参考文献">参考文献</h2>
<div id="refer-anchor-1">

</div>
<ul>
<li>[1] <a href="https://arxiv.org/abs/1604.00981" target="_blank" rel="noopener external nofollow noreferrer">Chen J, Pan X, Monga R, et al. Revisiting distributed synchronous SGD[J]. arXiv preprint arXiv:1604.00981, 2016.</a>
<div id="refer-anchor-2">

</div></li>
<li>[2] <a href="http://papers.nips.cc/paper/4894-more-effective-distributed-ml-via-as" target="_blank" rel="noopener external nofollow noreferrer">Ho Q, Cipar J, Cui H, et al. More effective distributed ml via a stale synchronous parallel parameter server[C]//Advances in neural information processing systems. 2013: 1223-1231.</a>
<div id="refer-anchor-3">

</div></li>
<li>[3] <a href="https://home.cse.ust.hk/~weiwa/papers/chen-infocom19.pdf" target="_blank" rel="noopener external nofollow noreferrer">Chen C, Wang W, Li B. Round-robin synchronization: Mitigating communication bottlenecks in parameter servers[C]//IEEE INFOCOM 2019-IEEE Conference on Computer Communications. IEEE, 2019: 532-540.</a>
<div id="refer-anchor-4">

</div></li>
<li>[4] <a href="https://ieeexplore.ieee.org/abstract/document/6484993/" target="_blank" rel="noopener external nofollow noreferrer">Mota J F C, Xavier J M F, Aguiar P M Q, et al. D-ADMM: A communication-efficient distributed algorithm for separable optimization[J]. IEEE Transactions on Signal Processing, 2013, 61(10): 2718-2723.</a>
<div id="refer-anchor-5">

</div></li>
<li>[5] <a href="https://ieeexplore.ieee.org/abstract/document/6425904/" target="_blank" rel="noopener external nofollow noreferrer">Wei E, Ozdaglar A. Distributed alternating direction method of multipliers[C]//2012 IEEE 51st IEEE Conference on Decision and Control (CDC). IEEE, 2012: 5445-5450.</a>
<div id="refer-anchor-6">

</div></li>
<li>[6] <a href="https://ieeexplore.ieee.org/abstract/document/7472585/" target="_blank" rel="noopener external nofollow noreferrer">Chang T H, Hong M, Liao W C, et al. Asynchronous distributed alternating direction method of multipliers: Algorithm and convergence analysis[C]//2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2016: 4781-4785.</a></li>
</ul>
<div id="refer-anchor-7">

</div>
<ul>
<li>[7] <a href="http://www.jmlr.org/proceedings/papers/v32/zhange14.pdf" target="_blank" rel="noopener external nofollow noreferrer">Zhang R, Kwok J. Asynchronous distributed ADMM for consensus optimization[C]//International conference on machine learning. 2014: 1701-1709.</a>
<div id="refer-anchor-8">

</div></li>
<li>[8] <a href="http://papers.nips.cc/paper/5597-communication-efficient-distributed-machine-learning-with-the-parameter-server" target="_blank" rel="noopener external nofollow noreferrer">Li M, Andersen D G, Smola A J, et al. Communication efficient distributed machine learning with the parameter server[C]//Advances in Neural Information Processing Systems. 2014: 19-27.</a>
<div id="refer-anchor-9">

</div></li>
<li>[9] <a href="https://arxiv.org/abs/1403.7550" target="_blank" rel="noopener external nofollow noreferrer">Zhang C, Ré C. Dimmwitted: A study of main-memory statistical analytics[J]. arXiv preprint arXiv:1403.7550, 2014.</a>
<div id="refer-anchor-10">

</div></li>
<li>[10] <a href="https://arxiv.org/abs/1603.04379" target="_blank" rel="noopener external nofollow noreferrer">Bijral A S, Sarwate A D, Srebro N. On data dependence in distributed stochastic optimization[J]. arXiv preprint arXiv:1603.04379, 2016.</a>
<div id="refer-anchor-11">

</div></li>
<li>[11] <a href="https://arxiv.org/abs/1606.07365" target="_blank" rel="noopener external nofollow noreferrer">Zhang J, De Sa C, Mitliagkas I, et al. Parallel SGD: When does averaging help?[J]. arXiv preprint arXiv:1606.07365, 2016.</a>
<div id="refer-anchor-12">

</div></li>
<li>[12] <a href="http://papers.nips.cc/paper/9288-local-sgd-with-periodic-averaging-tighter-analysis-and-adaptive-synchronization" target="_blank" rel="noopener external nofollow noreferrer">Haddadpour F, Kamani M M, Mahdavi M, et al. Local SGD with periodic averaging: Tighter analysis and adaptive synchronization[C]//Advances in Neural Information Processing Systems. 2019: 11082-11094.</a>
<div id="refer-anchor-13">

</div></li>
<li>[13] <a href="https://www.aclweb.org/anthology/N10-1069.pdf" target="_blank" rel="noopener external nofollow noreferrer">McDonald R, Hall K, Mann G. Distributed training strategies for the structured perceptron[C]//Human language technologies: The 2010 annual conference of the North American chapter of the association for computational linguistics. 2010: 456-464.</a>
<div id="refer-anchor-14">

</div></li>
<li>[14] <a href="http://papers.nips.cc/paper/3881-efficient-large-scale-distributed-training-of-conditional-maximum-entropy-models" target="_blank" rel="noopener external nofollow noreferrer">Mcdonald R, Mohri M, Silberman N, et al. Efficient large-scale distributed training of conditional maximum entropy models[C]//Advances in neural information processing systems. 2009: 1231-1239.</a>
<div id="refer-anchor-15">

</div></li>
<li>[15] <a href="https://ieeexplore.ieee.org/abstract/document/6853589/" target="_blank" rel="noopener external nofollow noreferrer">Zhang X, Trmal J, Povey D, et al. Improving deep neural network acoustic models using generalized maxout networks[C]//2014 IEEE international conference on acoustics, speech and signal processing (ICASSP). IEEE, 2014: 215-219.</a>
<div id="refer-anchor-16">

</div></li>
<li>[16] <a href="http://papers.nips.cc/paper/5761-deep-learning-with-elastic-averaging-sgd" target="_blank" rel="noopener external nofollow noreferrer">Zhang S, Choromanska A E, LeCun Y. Deep learning with elastic averaging SGD[C]//Advances in neural information processing systems. 2015: 685-693.</a>
<div id="refer-anchor-17">

</div></li>
<li>[17] <a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/4514" target="_blank" rel="noopener external nofollow noreferrer">Yu H, Yang S, Zhu S. Parallel restarted SGD with faster convergence and less communication: Demystifying why model averaging works for deep learning[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2019, 33: 5693-5700.</a>
<div id="refer-anchor-18">

</div></li>
<li>[18] <a href="https://arxiv.org/abs/1905.03817" target="_blank" rel="noopener external nofollow noreferrer">Yu H, Jin R, Yang S. On the linear speedup analysis of communication efficient momentum sgd for distributed non-convex optimization[J]. arXiv preprint arXiv:1905.03817, 2019.</a>
<div id="refer-anchor-19">

</div></li>
<li>[19] <a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/4514" target="_blank" rel="noopener external nofollow noreferrer">Yu H, Yang S, Zhu S. Parallel restarted SGD with faster convergence and less communication: Demystifying why model averaging works for deep learning[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2019, 33: 5693-5700.</a>
<div id="refer-anchor-20">

</div></li>
<li>[20] <a href="http://papers.nips.cc/paper/7519-a-linear-speedup-analysis-of-distributed-deep-learning-with-sparse-and-quantized-communication" target="_blank" rel="noopener external nofollow noreferrer">Jiang P, Agrawal G. A linear speedup analysis of distributed deep learning with sparse and quantized communication[C]//Advances in Neural Information Processing Systems. 2018: 2525-2536.</a>
<div id="refer-anchor-21">

</div></li>
<li>[21] <a href="https://arxiv.org/abs/1905.04346" target="_blank" rel="noopener external nofollow noreferrer">Yu H, Jin R. On the computation and communication complexity of parallel SGD with dynamic batch sizes for stochastic non-convex optimization[J]. arXiv preprint arXiv:1905.04346, 2019.</a>
<div id="refer-anchor-22">

</div></li>
<li>[22] <a href="http://papers.nips.cc/paper/5928-a-universal-catalyst-for-first-order-optimization" target="_blank" rel="noopener external nofollow noreferrer">Lin H, Mairal J, Harchaoui Z. A universal catalyst for first-order optimization[C]//Advances in neural information processing systems. 2015: 3384-3392.</a>
<div id="refer-anchor-23">

</div></li>
<li>[23] <a href="https://hal.inria.fr/hal-01773296/" target="_blank" rel="noopener external nofollow noreferrer">Paquette C, Lin H, Drusvyatskiy D, et al. Catalyst for gradient-based nonconvex optimization[C]. 2018.</a>
<div id="refer-anchor-24">

</div></li>
<li>[24] <a href="https://arxiv.org/abs/1808.07217" target="_blank" rel="noopener external nofollow noreferrer">Lin T, Stich S U, Patel K K, et al. Don't Use Large Mini-Batches, Use Local SGD[J]. arXiv preprint arXiv:1808.07217, 2018.</a>
<div id="refer-anchor-25">

</div></li>
<li>[25] <a href="http://proceedings.mlr.press/v70/suresh17a.html" target="_blank" rel="noopener external nofollow noreferrer">Suresh A T, Felix X Y, Kumar S, et al. Distributed mean estimation with limited communication[C]//International Conference on Machine Learning. 2017: 3329-3337.</a>
<div id="refer-anchor-26">

</div></li>
<li>[26] <a href="https://www.frontiersin.org/articles/10.3389/fams.2018.00062/full" target="_blank" rel="noopener external nofollow noreferrer">Konečný J, Richtárik P. Randomized distributed mean estimation: Accuracy vs. communication[J]. Frontiers in Applied Mathematics and Statistics, 2018, 4: 62.</a>
<div id="refer-anchor-27">

</div></li>
<li>[27] <a href="https://www.isca-speech.org/archive/interspeech_2014/i14_1058.html" target="_blank" rel="noopener external nofollow noreferrer">Seide F, Fu H, Droppo J, et al. 1-bit stochastic gradient descent and its application to data-parallel distributed training of speech dnns[C]//Fifteenth Annual Conference of the International Speech Communication Association. 2014.</a></li>
<li><div id="refer-anchor-28">

</div></li>
<li>[28] <a href="https://scholar.google.com.hk/scholar?hl=zh-CN&amp;as_sdt=0%2C5&amp;q=Qsgd%3A+Randomized+quantization+for+communication-optimal+stochastic+gradient+descent&amp;btnG=" target="_blank" rel="noopener external nofollow noreferrer">Alistarh D, Li J, Tomioka R, et al. Qsgd: Randomized quantization for communication-optimal stochastic gradient descent[J]. arXiv preprint arXiv:1610.02132, 2016.</a>
<div id="refer-anchor-29">

</div></li>
<li>[29] <a href="http://papers.nips.cc/paper/6749-terngrad-ternary-gradients-to-reduce-communication-in-distributed-deep-learning" target="_blank" rel="noopener external nofollow noreferrer">Wen W, Xu C, Yan F, et al. Terngrad: Ternary gradients to reduce communication in distributed deep learning[C]//Advances in neural information processing systems. 2017: 1509-1519.</a>
<div id="refer-anchor-30">

</div></li>
<li>[30] <a href="https://arxiv.org/abs/1802.04434" target="_blank" rel="noopener external nofollow noreferrer">Bernstein J, Wang Y X, Azizzadenesheli K, et al. signSGD: Compressed optimisation for non-convex problems[J]. arXiv preprint arXiv:1802.04434, 2018.</a>
<div id="refer-anchor-31">

</div></li>
<li>[31] <a href="https://arxiv.org/abs/1810.05291" target="_blank" rel="noopener external nofollow noreferrer">Bernstein J, Zhao J, Azizzadenesheli K, et al. signSGD with majority vote is communication efficient and fault tolerant[J]. arXiv preprint arXiv:1810.05291, 2018.</a>
<div id="refer-anchor-32">

</div></li>
<li>[32] <a href="http://papers.nips.cc/paper/8191-atomo-communication-efficient-learning-via-atomic-sparsification" target="_blank" rel="noopener external nofollow noreferrer">Wang H, Sievert S, Liu S, et al. Atomo: Communication-efficient learning via atomic sparsification[C]//Advances in Neural Information Processing Systems. 2018: 9850-9861.</a>
<div id="refer-anchor-33">

</div></li>
<li>[33] <a href="https://arxiv.org/abs/1901.09269" target="_blank" rel="noopener external nofollow noreferrer">Mishchenko K, Gorbunov E, Takáč M, et al. Distributed learning with compressed gradient differences[J]. arXiv preprint arXiv:1901.09269, 2019.</a>
<div id="refer-anchor-34">

</div></li>
<li>[34] <a href="http://papers.nips.cc/paper/8598-communication-efficient-distributed-learning-via-lazily-aggregated-quantified-grades" target="_blank" rel="noopener external nofollow noreferrer">Sun J, Chen T, Giannakis G, et al. Communication-efficient distributed learning via lazily aggregated quantized gradients[C]//Advances in Neural Information Processing Systems. 2019: 3370-3380.</a>
<div id="refer-anchor-35">

</div></li>
<li>[35] <a href="http://papers.nips.cc/paper/8694-double-quantization-for-communication-efficient-distributed-optimization" target="_blank" rel="noopener external nofollow noreferrer">Yu Y, Wu J, Huang L. Double quantization for communication-efficient distributed optimization[C]//Advances in Neural Information Processing Systems. 2019: 4438-4449.</a>
<div id="refer-anchor-36">

</div></li>
<li>[36] <a href="https://arxiv.org/abs/1905.10988" target="_blank" rel="noopener external nofollow noreferrer">Horvath S, Ho C Y, Horvath L, et al. Natural compression for distributed deep learning[J]. arXiv preprint arXiv:1905.10988, 2019.</a>
<div id="refer-anchor-37">

</div>
<div id="refer-anchor-38">

</div>
<div id="refer-anchor-27">

</div>
<div id="refer-anchor-27">

</div></li>
</ul>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/d05bdbcf.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/d05bdbcf.html" class="post-title-link" itemprop="url">Ray参数服务器性能测评实验</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-13 10:53:16" itemprop="dateCreated datePublished" datetime="2020-08-13T10:53:16+08:00">2020-08-13</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-28 19:39:01" itemprop="dateModified" datetime="2020-08-28T19:39:01+08:00">2020-08-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">分布式机器学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">分布式框架</span></a>
                </span>
            </span>

          
            <span id="/archives/d05bdbcf.html" class="post-meta-item leancloud_visitors" data-flag-title="Ray参数服务器性能测评实验" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/d05bdbcf.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/d05bdbcf.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>26k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>24 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          有东西被加密了, 请输入密码查看.
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/archives/d05bdbcf.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/71d33514.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/71d33514.html" class="post-title-link" itemprop="url">Konga前端修改设计调研</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-12 18:53:43" itemprop="dateCreated datePublished" datetime="2020-08-12T18:53:43+08:00">2020-08-12</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-13 10:52:26" itemprop="dateModified" datetime="2020-08-13T10:52:26+08:00">2020-08-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/API%E7%BD%91%E5%85%B3/" itemprop="url" rel="index"><span itemprop="name">API网关</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/API%E7%BD%91%E5%85%B3/Kong-Konga/" itemprop="url" rel="index"><span itemprop="name">Kong&Konga</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/API%E7%BD%91%E5%85%B3/Kong-Konga/%E6%9D%83%E9%99%90%E8%AE%A4%E8%AF%81/" itemprop="url" rel="index"><span itemprop="name">权限认证</span></a>
                </span>
            </span>

          
            <span id="/archives/71d33514.html" class="post-meta-item leancloud_visitors" data-flag-title="Konga前端修改设计调研" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/71d33514.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/71d33514.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>966</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="控制台">控制台</h2>
<p>控制台依然沿用Konga控制台，显示主要信息，明确信息的内容，检索有关节点通用的详细信息。</p>
<h2 id="主要信息">主要信息</h2>
<p>沿用Konga控制台，对Json解析以表格的方式进行显示可以沿用</p>
<h2 id="应用接入service">应用接入（Service）</h2>
<p>名称下方显示对该接口的主要描述</p>
<table>
<thead>
<tr class="header">
<th>名称</th>
<th>描述</th>
<th>协议</th>
<th>主机</th>
<th>端口</th>
<th>创建时间</th>
<th>DELETE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>查询企业信用信息</td>
<td>描述信息</td>
<td>HTTP</td>
<td>192.168.105.197</td>
<td>8080</td>
<td>2020/8/12</td>
<td>按钮</td>
</tr>
</tbody>
</table>
<p>Kong当中只支持英文名，所以这里新增加一列支持中文表示（因为Kong当中的名称可以为空，所以这里可以直接在Konga数据库中增加一列存储表示中文名），可以在中文名后面跟着英文名。</p>
<p>其他内容可以保持不变。</p>
<p>（英文名称可以用正则表达式固定采用_或者.号将地址/进行连接）</p>
<p>前面部分折叠按钮，点击之后显示该服务所有的路由会比较方便。</p>
<h3 id="新建应用">新建应用</h3>
<p>这里部分逻辑是二选一，填写了URL下面部分就空着，不填写URL，就填写下面部分。这里的设计可以更好一些？</p>
<p><img src="/archives/71d33514/image-20200812193442901.png" alt="image-20200812193442901" style="zoom:67%;"></p>
<h3 id="应用详情">应用详情</h3>
<p>应用详情、接管路由、插件、可访问的角色（查询可以访问该路由的角色，点击角色可以查看该角色下的所有用户）</p>
<h4 id="接管路由">接管路由</h4>
<table>
<thead>
<tr class="header">
<th>名称/英文名/ID</th>
<th>描述</th>
<th>协议</th>
<th>路径</th>
<th>方法</th>
<th>创建时间</th>
<th>DELETE/EDIT</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>查询企业信用信息</td>
<td>描述信息</td>
<td>HTTP</td>
<td>/breedtailwater/list</td>
<td>GET</td>
<td>2020/8/12</td>
<td>按钮</td>
</tr>
</tbody>
</table>
<h4 id="插件">插件</h4>
<p>这里最好有个按钮能够支持一键开关所有该服务下面的插件</p>
<p>方案：1、只能通过Kong官方API控制：http://192.168.105.197:1337/kong/plugins/3e29dc4f-fcca-461f-a57e-07c8b4104c83（缺点是多次请求，无法回滚）。2、开发一键开关插件的插件</p>
<table>
<thead>
<tr class="header">
<th>名称/英文名/ID</th>
<th>适用角色</th>
<th>适用角色</th>
<th>创建角色</th>
<th>按钮</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="可访问的角色">可访问的角色</h4>
<p>（暂时没有想到解决方法）</p>
<h2 id="api发布">API发布</h2>
<p>这块内容不要了，全放在应用接入当中，现在的逻辑不容易理解。</p>
<h2 id="角色权限">角色权限</h2>
<p>两块内容：所有用户+所有权限组</p>
<h3 id="用户">用户</h3>
<table>
<thead>
<tr class="header">
<th>用户名</th>
<th>所属权限组</th>
<th>...</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>fishfarm</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>这里也可以在Konga表中增加对于用户的描述</p>
<p>点击每个用户，进入之后大致保留其所有布局，点击组之后显示所有可以访问路由的脉络。</p>
<h3 id="权限组">权限组</h3>
<p>将权限组单独列出来，点击权限组显示所有该权限组中的用户信息（还没想到如何实现），如果通过数据库查询，这样的方式会导致KONGA和KONG的耦合度非常高，无法分离了。</p>
<p>隐藏负载均衡和HTTPS证书</p>

      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wjykl22.github.io/archives/d34fba27.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Jiyang">
      <meta itemprop="description" content="世界上有两样东西不可直视，一是太阳，二是人心">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="韭零后">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/archives/d34fba27.html" class="post-title-link" itemprop="url">LAQ和LAG代码研读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-08-06 15:53:47" itemprop="dateCreated datePublished" datetime="2020-08-06T15:53:47+08:00">2020-08-06</time>
            </span>
            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-12 19:00:12" itemprop="dateModified" datetime="2020-08-12T19:00:12+08:00">2020-08-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">分布式机器学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%9A%E4%BF%A1%E4%BC%98%E5%8C%96/" itemprop="url" rel="index"><span itemprop="name">通信优化</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%9A%E4%BF%A1%E4%BC%98%E5%8C%96/%E6%A2%AF%E5%BA%A6%E5%8E%8B%E7%BC%A9/" itemprop="url" rel="index"><span itemprop="name">梯度压缩</span></a>
                </span>
            </span>

          
            <span id="/archives/d34fba27.html" class="post-meta-item leancloud_visitors" data-flag-title="LAQ和LAG代码研读" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/archives/d34fba27.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/archives/d34fba27.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>62k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>56 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          此文加密，请输入密码
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/archives/d34fba27.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
    

            <ul class="sidebar-nav motion-element">
              <li class="sidebar-nav-toc">
                文章目录
              </li>
              <li class="sidebar-nav-overview">
                站点概览
              </li>
            </ul>
    



      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Jiyang"
      src="/img/avatar.jpg">
  <p class="site-author-name" itemprop="name">Jiyang</p>
  <div class="site-description" itemprop="description">世界上有两样东西不可直视，一是太阳，二是人心</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">24</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/wjykl22" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;wjykl22" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:wjykl22@gmail.com" title="E-Mail → mailto:wjykl22@gmail.com" rel="noopener external nofollow noreferrer" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



    <div class="links-of-blogroll motion-element links-of-blogroll-block">
      <div class="links-of-blogroll-title">
        <!-- modify icon to fire by szw -->
        <i class="fa fa-history fa-" aria-hidden="true"></i>
        近期文章
      </div>
      <ul class="links-of-blogroll-list">
        
        
          <li>
            <a href="/archives/5c29dc6b.html" title="AccPar: Tensor Partitioning for Heterogeneous Deep Learning Accelerators" target="_blank">AccPar: Tensor Partitioning for Heterogeneous Deep Learning Accelerators</a>
          </li>
        
          <li>
            <a href="/archives/740c8dcf.html" title="Alpha策略" target="_blank">Alpha策略</a>
          </li>
        
          <li>
            <a href="/archives/40cbe9ff.html" title="Device Placement Optimization with Reinforcement Learning" target="_blank">Device Placement Optimization with Reinforcement Learning</a>
          </li>
        
          <li>
            <a href="/archives/60fdd68b.html" title="Communication Optimal Parallel Multiplication of Sparse Random Matrices" target="_blank">Communication Optimal Parallel Multiplication of Sparse Random Matrices</a>
          </li>
        
          <li>
            <a href="/archives/62b3642.html" title="Beyond Data and Model Parallelism for Deep Neural Networks" target="_blank">Beyond Data and Model Parallelism for Deep Neural Networks</a>
          </li>
        
      </ul>
    </div>



        <!--网易云音乐-->
        <div id="music163player">
        	<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=110 src="//music.163.com/outchain/player?type=0&id=5283780459&auto=1&height=90"></iframe>
        	</iframe>
        </div>
        	  <!--/网易云音乐-->

      </div>
      <div style="">
  <canvas id="canvas" style="width:60%;">当前浏览器不支持canvas，请更换浏览器后再试</canvas>
</div>
<script>
(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*更新时钟*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //时间发生变化
            if(NewData[i] !== data[i]){
                //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //增加小球
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*渲染*/
    function render(){
        //重置画布宽度，达到清空画布的效果
        canvas.height = 100;
        //渲染时钟
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //渲染小球
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //更新时钟
        updateDigitTime();
        //更新小球状态
        updateBalls();
        //渲染
        render();
    },50);
}

})();
</script>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-eye"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jiyang</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">264k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">4:01</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener external nofollow noreferrer" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener external nofollow noreferrer" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_lines.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : true,
      appId      : 'owd5pfJvVjoBkwE0F3w7Oqc5-gzGzoHsz',
      appKey     : 'pQbK5JId2AmEfxG3oSiFXAFP',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>
<div class="moon-menu">
  <div class="moon-menu-items">
    
    <div class="moon-menu-item" onclick="back2bottom()">
      <svg aria-hidden="true" focusable="false" data-prefix="fa" data-icon="chevron-down" class="svg-inline--fa fa-chevron-down fa-w-14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"></path></svg>    </div>
    
    <div class="moon-menu-item" onclick="back2top()">
      <svg aria-hidden="true" focusable="false" data-prefix="fa" data-icon="chevron-up" class="svg-inline--fa fa-chevron-up fa-w-14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M240.971 130.524l194.343 194.343c9.373 9.373 9.373 24.569 0 33.941l-22.667 22.667c-9.357 9.357-24.522 9.375-33.901.04L224 227.495 69.255 381.516c-9.379 9.335-24.544 9.317-33.901-.04l-22.667-22.667c-9.373-9.373-9.373-24.569 0-33.941L207.03 130.525c9.372-9.373 24.568-9.373 33.941-.001z"></path></svg>    </div>
    
  </div>
  <div class="moon-menu-button" onclick="moonMenuClick()">
    <svg class="moon-menu-svg">
      <circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle>
      <circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle>
      <g class="moon-menu-points">
        <circle class="moon-menu-point" r=".2rem" cx="0" cy="-.8rem"></circle>
        <circle class="moon-menu-point" r=".2rem"></circle>
        <circle class="moon-menu-point" r=".2rem" cx="0" cy=".8rem"></circle>
      </g>
    </svg>
    <div class="moon-menu-icon">
    </div>
    <div class="moon-menu-text">
    </div>
  </div>
</div>
<script src="/js/injector.js"></script>
</body>
</html>
